# 大模型、强化学习与运筹学与城市交通

本文档由 40 个页面合并而成

---

## 页面 1

# 文献综述 版本 1

## 基于大模型、强化学习与运筹学的城市交通研究

### 摘要

随着城市化进程的加速和智能交通系统(ITS)的飞速发展,城市交通面临着前所未有的挑战,如交通拥堵、环境污染和资源分配不均等。传统的交通管理方法往往难以适应复杂多变的交通环境。近年来,大规模语言模型(LLMs)、强化学习(RL)和运筹学(OR)作为前沿技术,为解决这些挑战提供了新的视角和强大的工具。本文旨在对基于大模型、强化学习与运筹学的城市交通研究进行全面的文献综述。首先,我们探讨了大规模语言模型在城市交通模拟、行为建模和决策支持方面的新兴应用,揭示了其在处理复杂非结构化数据和提供情境感知能力方面的潜力。其次,我们深入分析了强化学习在智能交通系统中的核心作用,涵盖了交通流管理、信号控制、共享出行调度、自动驾驶决策以及交通行为分析与预测等多个关键领域,并对不同强化学习算法的优势与局限性进行了比较。再次,本文详细阐述了运筹学方法在城市交通优化中的基础性地位,并重点关注了其与机器学习、强化学习相结合的混合方法,以解决动态路由、资源分配、网络建模和系统级优化等复杂问题。最后,本文总结了当前研究的主要发现,指出了现有研究的局限性,并展望了未来研究方向,包括构建更鲁棒的混合模型、提升模型可解释性、应对数据隐私挑战以及探索数字孪生等前沿技术在城市交通领域的应用。

### 关键词

大规模语言模型 (LLMs)、强化学习、运筹学、智能交通系统

### 引言

城市交通系统是现代城市运行的动脉,其效率和可持续性直接关系到居民的生活质量和经济社会的发展。然而,随着城市人口的持续增长、机动车保有量的不断攀升以及共享经济模式的兴起,城市交通系统正面临着日益严峻的挑战,包括严重的交通拥堵、停车困难、交通事故频发、能源消耗巨大以及环境污染加剧等。这些问题不仅降低了交通系统的整体效率,也对城市的可持续发展构成了威胁。传统的交通管理和规划方法,如基于固定时间或规则的信号控制、静态的路径规划以及人工干预的调度策略,在应对高度动态、不确定且复杂的城市交通环境时,往往显得力不从心,难以实现全局最优和实时响应。

为了克服传统方法的局限性,智能交通系统(ITS)应运而生,旨在通过集成先进的信息、通信和控制技术,提升交通系统的安全性、效率和可持续性。近年来,随着人工智能技术的飞速发展,特别是大规模语言模型(LLMs)、强化学习(RL)和运筹学(OR)等前沿理论与方法的深度融合,为城市交通研究带来了革命性的突破。大规模语言模型以其强大的自然语言理解和生成能力,为交通行为建模、情

---

## 页面 2

同时借助 ML/RL 处理数据驱动的复杂性和动态性, 实现了更高效、更鲁棒的解决方案。

尽管这些技术取得了显著进展, 但城市交通研究仍面临诸多挑战和研究缺口: (1) **数据挑战**: 城市交通数据具有多源异构、海量、动态、不完整和噪声等特点。如何有效地整合、清洗和利用这些数据, 特别是非结构化数据, 以支持 LLMs 和 RL 模型的训练和推理, 是一个持续的挑战。同时, 数据隐私和安全问题在处理敏感出行数据时也至关重要。(2) **模型可解释性与鲁棒性**: 深度学习和强化学习模型往往是“黑箱”模型, 其决策过程缺乏透明度。在交通管理等关键领域, 理解模型为何做出特定决策对于建立信任和确保安全至关重要。未来的研究需要探索可解释人工智能(XAI)技术, 如 Ramesh et al. (2025) 所强调的, 以提升模型的透明度和可靠性。此外, 模型在面对未知或极端交通状况时的鲁棒性也需进一步提升。(3) **实时性与可扩展性**: 城市交通系统需要实时响应, 而许多先进模型(特别是 LLMs 和复杂的 MARL 模型)的计算开销巨大, 难以满足实时性要求。如何设计轻量级、高效的模型, 并利用分布式计算、边缘计算等技术实现大规模交通系统的实时优化, 是亟待解决的问题。(4) **多目标优化与公平性**: 城市交通问题往往涉及多个相互冲突的目标, 如效率、安全、公平、环境友好等。如何设计有效的多目标优化框架, 并在不同目标之间进行权衡, 特别是确保交通资源分配的公平性(如 Liang (2024) 所关注的司机收入公平性), 是未来研究的重要方向。(5) **理论与实践的鸿沟**: 尽管学术研究取得了丰硕成果, 但许多先进模型在实际交通系统中的部署和应用仍面临挑战, 包括数据获取、系统集成、政策法规和公众接受度等。未来的研究需要更加注重模型的实用性和可操作性, 加强与交通管理部门和行业企业的合作。(6) **数字孪生与虚实融合**: 结合数字孪生技术, 构建城市交通系统的虚拟副本, 可以为 LLMs、RL 和 OR 模型提供一个安全、可控的实验平台, 进行策略测试和优化。通过虚实融合, 可以实现对交通系统的实时监测、预测和控制, 进一步提升智能交通系统的智能化水平。

展望未来, 城市交通研究将朝着以下几个方向发展: (1) **更深层次的混合智能**: 进一步探索 LLMs、RL 和 OR 的深度融合机制, 例如利用 LLMs 进行交通情境理解和高级规划, RL 进行实时决策和控制, OR 提供优化框架和约束。构建能够无缝集成不同技术优势的统一智能框架。(2) **可解释与可信赖的 AI**: 发展针对交通场景的 XAI 方法, 使模型的决策过程透明化, 增强交通管理人员和公众对智能系统的信任。同时, 加强模型的安全性和鲁棒性研究, 确保在关键交通应用中的可靠性。(3) **边缘智能与联邦学习**: 针对交通数据的分布式特性和隐私需求, 探索在边缘设备上部署轻量级 AI 模型, 并利用联邦学习等技术在保护数据隐私的前提下进行模型训练和更新。(4) **人机协作与情境感知**: 发展能够与人类交通管理者有效协作的智能系统, 利用 LLMs 理解人类指令和意图, RL 提供决策建议, 最终实现人机协同的智能交通管理。(5) **可持续交通与韧性城市**: 将环境因素、能源消耗和城市韧性纳入优化目标, 利用 AI 技术设计更可持续、更能抵御突发事件(如自然灾害、疫情)的城市交通系统。

---

## 页面 3

# 结论

本文对基于大规模语言模型、强化学习与运筹学的城市交通研究进行了全面的文献综述。我们发现，这三种前沿技术正共同推动智能交通系统向更智能、高效和可持续的方向发展。大规模语言模型在处理非结构化数据、模拟人类行为和提供情境感知决策支持方面展现出巨大潜力，能够提升交通模拟的真实性和决策的精细度。强化学习则以其强大的自适应学习和实时决策能力，在交通流管理、信号控制、共享出行调度、自动驾驶决策以及交通行为分析与预测等多个关键领域取得了显著进展，有效应对了城市交通的动态性和不确定性。运筹学作为优化决策的理论基石，其与机器学习和强化学习的深度融合，为解决动态路由、资源分配、网络建模和系统级优化等复杂问题提供了强大的混合解决方案，弥补了单一方法在处理大规模、动态和不确定性问题时的不足。

尽管取得了显著成就，当前研究仍面临诸多挑战，包括数据整合与隐私保护、模型可解释性与鲁棒性、实时性与可扩展性、多目标优化与公平性权衡以及理论与实践之间的鸿沟。未来的研究应致力于构建更深层次的混合智能框架，将 LLMs的情境理解能力、RL的动态决策能力和OR的优化理论优势无缝集成。同时，发展可解释和可信赖的AI技术，确保智能交通系统的安全性和透明度至关重要。此外，探索边缘智能、联邦学习、人机协作以及数字孪生等前沿技术，将有助于应对数据挑战、提升系统效率和实现更具韧性的城市交通管理。通过持续的跨学科研究和技术创新，我们有望构建一个更加智能、高效、安全和可持续的未来城市交通系统。

## 文献综述 版本 2

# 基于大模型、强化学习与运筹学的城市交通研究

## 摘要

随着全球城市化进程的加速和智能交通系统(ITS)的蓬勃发展，城市交通面临着前所未有的复杂挑战，包括交通拥堵、环境污染、资源分配不均以及出行效率低下等。传统交通管理方法往往难以适应动态变化的交通环境，亟需创新性的解决方案。
近年来，大规模语言模型(LLMs)、强化学习(RL)和运筹学(OR)作为人工智能和决策科学领域的前沿技术，为解决城市交通问题提供了强大的新范式。本综述旨在系统性地梳理和分析当前基于LLMs、RL和OR在城市交通研究中的最新进展。我们首先探讨了LLMs在宏观交通模拟和行为建模中的潜力，强调其在生成复杂出行链和情境感知调整方面的独特优势。其次，我们深入剖析了强化学习在交通信号控制、车队调度、路径优化以及公平性考量等微观和中观层面的广泛应用，并对比了不同RL算法在解决动态、不确定性问题上的表现。接着，我们审视了运筹学作为经典优化工具在交通规划和资源分配中的基础作用，并重点关注了其与机器学习和强化学习相结合的混合方法，如何有效应对大规模组合优化难题。通过对现有文献的综合分析，本综述揭示了这些技术在提升交通效率、保障公平性、增强系统韧性方面的显著贡献，同时也指出了当前研究面临的挑战，包括数据依赖、模

---

## 页面 4

型可解释性、计算复杂性以及多目标优化等。最后,我们展望了未来研究方向,强
调了跨学科融合、多智能体协同、真实世界部署以及伦理与隐私保护的重要性,以
期为构建更加智能、高效和可持续的城市交通系统提供理论指导和实践启示。

**关键词:** 大规模语言模型(LLMs)、强化学习、运筹学、智能交通系统

引言

城市交通系统是现代城市运行的动脉,其效率和可持续性直接关系到居民的生活质量和经济社会的健康发展。然而,随着城市人口的持续增长和机动车保有量的不断攀升,交通拥堵、交通事故、环境污染以及能源消耗等问题日益严峻,给城市管理者带来了巨大的挑战。传统的交通管理和规划方法,如基于规则的信号控制、静态的路线规划等,往往难以有效应对交通流的动态性、随机性和复杂性。因此,开发能够实时感知、智能决策和自适应优化的新型交通管理范式变得至关重要。

近年来,人工智能(AI)技术的飞速发展为解决城市交通问题带来了革命性的机遇。其中,大规模语言模型(LLMs)、强化学习(RL)和运筹学(OR)作为AI和决策科学领域的核心支柱,正日益成为智能交通系统(ITS)研究的热点。大规模语言模型以其强大的自然语言理解和生成能力,在宏观交通行为建模、情境感知模拟以及用户交互方面展现出巨大潜力。强化学习则通过智能体与环境的交互学习,在动态、不确定性的交通环境中实现最优决策,尤其适用于交通信号控制、车队调度和路径优化等任务。运筹学作为一门经典的优化科学,为交通规划、资源分配和物流管理提供了坚实的理论基础和高效的算法工具,其在解决大规模组合优化问题方面具有不可替代的价值。将这三者有机结合,有望构建出更具鲁棒性、适应性和智能化的城市交通解决方案。

本综述旨在全面审视和分析当前基于大规模语言模型、强化学习与运筹学在城市交通研究中的最新进展。我们将系统地梳理相关文献,按照研究主题和方法进行分类讨论,深入探讨每种方法的核心思想、技术细节、应用场景及其在解决城市交通问题中的优势与局限性。具体而言,本综述将重点关注以下几个方面:首先,LLMs如何被用于模拟复杂的城市出行行为和生成逼真的交通场景;其次,强化学习如何通过学习最优策略来动态优化交通流、调度交通工具并提升系统效率;再次,运筹学如何为交通决策提供优化框架,以及其与机器学习和强化学习的融合如何克服传统方法的局限性;最后,我们将对现有研究进行批判性分析,识别当前的研究空白和挑战,并展望未来的研究方向,以期为推动智能城市交通系统的发展提供有益的见解。

相关工作

城市交通研究是一个多学科交叉的领域,长期以来,运筹学提供了坚实的理论基础
和优化工具,而随着计算能力的提升和数据量的爆炸式增长,机器学习尤其是深度

---

## 页面 5

学习和强化学习,为解决交通系统的动态性和不确定性问题开辟了新途径。近年来,大规模语言模型(LLMs)的兴起,则为交通行为建模和情境感知模拟带来了前所未有的可能性。本节将从这三个核心技术范式出发,结合智能交通系统(ITS)的背景,对相关研究进行分类阐述。

# 运筹学在城市交通中的基础与演进

运筹学作为一门应用数学学科,其核心在于利用数学模型和优化算法来解决复杂的
决策问题,在城市交通领域具有悠久的应用历史和深远的影响。从经典的交通流理
论、网络均衡模型到车辆路径问题(VRP)和资源分配问题,运筹学为交通规划、
管理和运营提供了不可或缺的理论框架和解决方案。

在交通规划层面,运筹学模型被广泛用于需求预测、网络设计和设施选址。例如,
在自行车共享系统的静态再平衡操作中,准确预测自行车的需求和投放量是维持高
服务水平的关键。J. Liu et al. (2024)提出了一种数据驱动的优化框架,用于解决自
行车共享系统中的静态再平衡问题。该框架首先开发了基于深度学习的预测器,以
捕捉站点级别需求的时序依赖性、天气条件的影响以及附近站点的需求替代效应。
基于这些预测的需求率,他们进一步开发了一个基于序列模拟的需求损失估计器,
以确定能够最小化预期需求损失的最优再平衡数量。这体现了运筹学与机器学习在
需求预测和优化决策上的紧密结合。在车辆路径优化方面,运筹学提供了丰富的模
型和算法,如旅行商问题(TSP)、车辆路径问题(VRP)及其各种变体。然而,
当问题规模增大或环境动态变化时,传统运筹学算法的计算复杂度会急剧上升。例
如,异构容量车辆路径问题(HCVRP)在城市杂货配送中是一个关键挑战,需要
优化具有不同容量和速度的异构车队路线以高效满足客户需求。S. Li et al. (2025)
指出,传统的精确算法和启发式算法在扩展到更大规模问题时会遇到显著的计算障
碍。这促使研究者寻求将运筹学与机器学习相结合的方法,以提高求解效率和质量。

在动态决策和资源分配方面,运筹学中的马尔可夫决策过程(MDP)是建模随机
动态系统的重要工具。然而,MDP面临“维度灾难”的挑战,尤其是在状态空间
和动作空间巨大时。Neria & Tzur (2024)在研究具有公平性问题的动态取货和分配
问题时,将其建模为一个随机动态路径和资源分配问题,目标是在尽可能多地交付
货物的同时实现对需求点的公平分配。尽管他们提出了一个MDP公式,但承认其
存在维度灾难问题。为了克服这一限制,他们开发了一个启发式框架,将运筹学和
机器学习进行了新颖的结合,具体使用了大规模邻域搜索(LNS)来探索可能的决
策,并结合神经网络(NN)模型来近似给定任何状态和动作的未来价值。这种混
合方法展示了运筹学在问题建模上的优势,以及机器学习在处理复杂性和不确定性
方面的潜力。

运筹学在交通系统中的应用还延伸到更复杂的系统优化,例如地铁乘客路径选择建
模。Du et al. (2025)提出了一种新颖的乘客路径选择模型,该模型包含一个考虑乘
客流量、排队、拥堵和换乘延误的地铁模拟器。为了校准模型,他们提出了一种数
据驱动的方法,利用完全可微分的基于模拟的优化(SBO)框架,通过迭代反向传
播(IB)算法自动分析性地计算梯度。该SBO框架整合了智能卡数据和列车载荷

---

## 页面 6

等多源数据,以校准最能匹配观测数据的路径选择参数。这种方法将运筹学中的优化思想与现代机器学习的自动微分能力相结合,实现了对大规模参数的有效校准,并能扩展到用户均衡(UE)公式,考虑拥堵感知的路径选择模型。

总的来说,运筹学为城市交通研究提供了坚实的理论基础和优化工具,尤其在静态规划和结构化问题上表现出色。然而,面对城市交通日益增长的动态性、不确定性和大规模复杂性,传统运筹学方法在计算效率和适应性方面面临挑战。这促使研究者积极探索将运筹学与机器学习、强化学习等先进技术相结合,以构建更强大、更灵活的解决方案。

# 强化学习在城市交通中的应用与突破

强化学习(RL)作为一种通过与环境交互学习最优策略的机器学习范式,在处理动态、不确定性以及序列决策问题方面具有天然优势,使其成为智能交通系统(ITS)领域的研究热点。RL在城市交通中的应用涵盖了从微观的交通信号控制到宏观的车队管理和交通流优化等多个层面。

## 交通信号控制与交通流优化

交通信号控制是城市交通管理的核心环节,其目标是优化交叉口通行效率,减少车辆和行人的等待时间。传统的信号控制方法多基于固定配时或感应控制,难以适应实时变化的交通状况。RL通过将信号控制器视为智能体,将交通状态(如排队长度、车辆密度)作为观测,将信号配时方案作为动作,将交通效率指标(如平均等待时间、吞吐量)作为奖励,从而学习最优的信号控制策略。

Han et al. (2022) 提出了一种考虑行人行为的深度强化学习(DRL)交通信号控制方法。他们指出,大多数信号控制优化仅以最大化交通容量为目标,而忽略了交叉口行人的关注。为了解决这一问题,他们的方法结合了强化学习网络和交通信号控制策略,同时考虑了交通效率和安全方面,并纳入了行人和车辆通过交叉口的等待时间。通过应用和改进离散交通状态编码(DTSE)方法来定义更全面的状态和奖励,并在SUMO仿真环境中进行实验,结果表明该方法显著减少了等待时间和等待人数,优于Dueling DQN等传统方法。这凸显了RL在多目标优化(效率与安全、车辆与行人)方面的潜力。

类似地,Voronovskyi & Yurchak (2025)分析了旨在优化城市交通的智能交通系统(ITS)的现代方法,并特别关注了在动态道路交通条件下用于控制交通灯的无模型强化学习算法(Q-Learning 和 Deep Q-Learning)。他们在SUMO环境中的仿真结果证明,实施此类算法显著减少了交叉口排队并增加了交通网络的容量。特别是,Deep Q-Learning 能够更有效地处理大量数据,包括来自物联网(IoT)传感器和车联网(V2X)技术的信息,从而促进对不断变化的交通状况的现实适应。这进一步证实了DRL在交通信号控制中的有效性,并强调了其与现代传感技术结合的重要性。

---

## 页面 7

除了单一交叉口,RL也被扩展到多交叉口协同控制。N & A (2025) 提出了一种混合优势 Actor-Critic (A2C)算法,用于实时交通优化,以解决交通拥堵和事故问题。他们指出,DQN 和 Q-learning 等基于机器学习的交通控制方法在训练稳定性、实时适应性和可扩展性方面存在挑战。A2C算法通过结合基于策略和基于价值的强化学习,使系统能够更快地学习、实时适应并实现一致且可扩展的性能。实验结果表明,该策略在减少等待时间、事故和交通拥堵方面表现出色,展示了RL在提升交通安全和效率方面的强大能力。

## 车队管理与调度

在共享出行、网约车和自动驾驶出租车(Robo-taxi)等新兴交通服务中,高效的车队管理和调度是提升服务质量和运营效率的关键。RL能够处理这些系统中的动态供需匹配、车辆重新平衡和路径规划等复杂问题。

Tresca et al. (2025) 针对自动驾驶移动按需(AMoD)系统的Robo-taxi 车队协调问题,提出了一种新颖的决策框架,将数学建模与数据驱动技术相结合。他们通过强化学习的视角呈现AMoD协调问题,并提出了一个基于图网络的框架,该框架利用了图表示学习、强化学习和经典运筹学工具的主要优势。在各种仿真场景下的广泛评估表明,该方法在系统性能、计算效率和泛化能力方面均优于现有方法,展示了RL在复杂大规模车队协调中的强大潜力,特别是与图神经网络结合时,能够有效捕捉交通网络的拓扑结构和动态关系。

Liang (2024) 关注网约车匹配中的公平性问题,提出了一种面向公平性的动态网约车匹配算法。他们指出,现有研究缺乏对司机收入公平性的探索,且部分算法在工业背景下不具实用性。该算法有效优化了平台整体效率(预期总司机收入)和司机收入公平性(加权摊销公平性信息熵)。通过引入匹配结果对后续匹配的时间依赖性,并使用强化学习来预测这些时间依赖性,克服了传统匹配算法仅依赖历史数据和当前情况进行订单分配的局限性。此外,他们还实施了一系列优化解决方案,包括引入时间窗匹配模型、剪枝操作和度量表示调整,以增强算法对大规模数据集的适应性和可扩展性。实验结果表明,该算法在公平性、平台效用和匹配效率方面均优于传统算法,强调了RL在多目标优化(效率与公平性)和处理时间依赖性方面的优势。

在异构车队路径规划方面,S. Li et al. (2025) 提出了一种基于深度强化学习的新型神经网络架构,用于优化异构容量车辆路径问题(HCVRP)。该方法引入了Linformer 以显著降低计算需求,并设计了多关系节点选择解码器以提高决策过程的准确性和效率。通过广泛实验,他们的DRL框架在提供卓越的解决方案质量和计算效率方面,持续超越传统启发式算法和现有DRL模型。这表明DRL能够有效解决传统运筹学在处理大规模、复杂VRP问题时的计算瓶颈,通过学习启发式策略来生成高质量的解决方案。

## 交通行为建模与预测

RL不仅可以用于直接控制交通系统,还可以用于理解和预测交通参与者的行为。

---

## 页面 8

Taherinavid et al. (2024) 提出了一种基于深度强化学习的自动交通模式分类模型, 利用智能手机传感器数据(加速度计、磁力计和陀螺仪)。该模型通过人工神经网络(ANN)增强特征,并将分类任务视为一系列结构化的决策事件。其创新之处在于采用改进的差分进化(DE)算法初始化权重,并设计了专门的智能体-环境关系,通过奖励机制鼓励对不频繁模式的准确分类。在HTC 数据集上的评估显示出高准确率和F-measure,证明了DRL在从复杂传感器数据中学习并进行高精度分类方面的有效性,这对于健康监测和城市规划等领域至关重要。

M. Li et al. (2025) 综述了强化学习在交通流量预测(TFP)中的应用,指出了传统TFP 方法难以捕捉交通网络中交通空间分布与各位置交通状况时间演变之间的相互依赖关系(时空相关性,SCTF)。文章总结了深度学习和强化学习在TFP中的模型,并全面比较了各种方法的优缺点。实验结果表明,RL能够更大程度地减少车辆排队时间和平均延误,并缓解空气污染。这表明RL不仅可以用于实时控制,其学习到的策略和价值函数也可以为预测任务提供有价值的信息,尤其是在考虑动态交互和决策影响时。

## 其他 RL 应用与挑战

RL 的应用还扩展到电动汽车(EVs)与电网的集成。Dong et al. (2023) 提出了一种多智能体强化学习(MARL)机制,用于调度电动汽车电池的日间放电过程,以优化电网的削峰性能。该 MARL 克服了能源预测的不准确性,允许智能体(即电动汽车)做出自主决策。这些智能体以集中式方式进行训练,但进行本地决策以保持自主性和隐私。这展示了 MARL 在分布式资源管理和优化中的潜力,同时兼顾了隐私和去中心化决策的需求。

尽管强化学习在城市交通领域取得了显著进展,但仍面临一些挑战。Khalil et al. (2024) 在其关于智能交通系统先进学习技术的综述中,强调了ITS在高度复杂和动态环境中运行的特点,并指出了建模元素之间复杂交互、创建通用表示以及将其应用于交通问题所面临的挑战。他们探讨了深度学习和LLMs在ITS中的潜在应用,包括交通流预测、车辆检测和分类、道路状况监测、交通标志识别和自动驾驶车辆。同时,他们也识别了未来的挑战和研究方向,如迁移学习、混合模型、隐私和安全以及超可靠低延迟通信,这些挑战同样适用于强化学习的应用。RL模型通常需要大量的训练数据和计算资源,在真实世界中部署时面临安全性、可解释性和泛化能力等问题。此外,多智能体RL中的协作与竞争、奖励函数设计以及状态空间和动作空间的维度灾难等问题,仍然是当前研究的重点和难点。

## 大规模语言模型 (LLMs) 在城市交通中的新兴作用

大规模语言模型(LLMs)的出现,标志着人工智能领域的一个里程碑,其在自然语言理解、生成和推理方面的卓越能力,正逐步渗透到包括城市交通在内的各个应用领域。虽然 LLMs 在交通领域的直接应用尚处于早期阶段,但其在模拟人类行为、情境感知以及提供智能交互方面的潜力已引起广泛关注。

---

## 页面 9

# 宏观出行行为模拟与情境感知

传统的城市交通模拟往往依赖于复杂的数学模型和大量的经验参数,这些模型在捕捉人类出行行为的细微差别和情境依赖性方面存在局限。LLMs 以其对海量文本数据的学习,能够理解和生成具有高度语义连贯性和情境相关性的文本,这为模拟更真实、更具适应性的人类出行行为提供了新的视角。

Liu et al. (2025) 提出了 MobiVerse,一个混合框架,旨在通过结合轻量级领域特定生成器和大规模语言模型来扩展城市出行模拟。他们指出,传统的基于活动链的模型需要大量数据收集和手动校准,而机器学习方法难以适应动态条件,基于智能体的LLMs 实现则面临大规模模拟的计算限制。MobiVerse 通过利用轻量级领域特定生成器生成基础活动链的效率,以及LLMs 进行情境感知修改的适应性,弥补了这一关键空白。在洛杉矶韦斯特伍德的案例研究中,MobiVerse 能够高效地为约53,000名居民生成并动态调整日程,使其智能体能够响应环境反馈,如道路封闭、大型集会活动和交通拥堵。这展示了LLMs 在宏观层面模拟复杂城市出行模式、生成逼真活动链以及实现情境感知调整的巨大潜力,为交通规划和政策评估提供了更灵活、更真实的模拟平台。LLMs 的引入使得模拟中的智能体能够以更接近人类的方式理解和响应环境变化,从而提升了模拟的真实性和预测能力。

# LLMs 在智能交通系统中的潜在应用

除了宏观模拟,LLMs 在智能交通系统(ITS)的多个方面也展现出广阔的应用前景。Khalil et al. (2024) 在其关于ITS先进学习技术的全面综述中,专门探讨了深度学习和大规模语言模型(LLMs)在ITS中的潜在应用。他们指出,LLMs 可以应用于交通流预测、车辆检测和分类、道路状况监测、交通标志识别以及自动驾驶车辆等领域。LLMs 的自然语言理解能力可以用于处理交通相关的文本数据,例如社交媒体上的交通报告、用户反馈、新闻事件等,从而为交通管理部门提供更全面的情境感知。此外,LLMs还可以作为智能交通助手的核心,通过自然语言接口与用户进行交互,提供个性化的出行建议、路线规划和实时交通信息。例如,用户可以通过语音或文本查询“去机场最快的路线是什么?”或者“附近哪里有停车位?”,LLMs可以理解这些查询并结合实时交通数据和用户偏好给出智能响应。

LLMs 在 ITS 中的应用还可能包括:
1. 交通事件检测与分析:通过分析新闻报道、社交媒体帖子和传感器数据中的文本信息,LLMs可以识别交通事件(如事故、施工、特殊活动),并评估其对交通流的影响。
2. 政策制定与评估支持:LLMs可以帮助分析交通政策文本,理解其潜在影响,并根据历史数据和模拟结果生成政策建议。
3. 用户体验增强:为出行者提供更自然、更智能的交互界面,例如通过聊天机器人提供个性化出行服务、处理投诉或提供紧急援助。
4. 自动驾驶决策辅助:虽然LLMs不直接控制车辆,但它们可以处理和理解来自车辆传感器、地图数据和外部信息源的复杂情境描述,为自动驾驶系统提供高层次的决策支持和情境理解。

---

## 页面 10

## 挑战与展望

尽管 LLMs 在城市交通领域展现出巨大潜力,但其应用仍面临诸多挑战。首先, LLMs 的训练需要海量的文本数据,而交通领域的特定语料库相对稀缺,可能需要进行领域适应性训练。其次,LLMs 的计算资源需求巨大,在实时交通决策中部署可能存在延迟问题。再次,LLMs 的“黑箱”特性使其决策过程难以解释,这在对安全性要求极高的交通领域是一个严重问题。最后,LLMs 可能存在“幻觉”现象,即生成看似合理但实际上不准确或虚假的信息,这在交通决策中是不可接受的。

未来的研究需要关注如何将 LLMs 的强大语言理解和生成能力与交通领域的专业知识、实时数据和优化算法相结合。例如,可以探索将 LLMs 作为高级规划器,生成高层次的交通管理策略或出行建议,然后由强化学习或运筹学模型进行细化和执行。同时,开发轻量级、可解释的 LLMs 模型,并结合知识图谱等结构化信息,以提高其在交通场景中的准确性和可靠性,将是重要的研究方向。此外,如何确保 LLMs 在交通应用中的数据隐私和伦理问题,也是需要深入探讨的议题。

## 运筹学、强化学习与大模型的融合：构建智能交通系统的协同范式

在城市交通研究中,运筹学、强化学习和大规模语言模型各自拥有独特的优势,但它们并非孤立存在,而是日益呈现出融合发展的趋势。这种融合旨在结合三者的长处,克服单一方法的局限性,从而构建更全面、更强大、更智能的城市交通解决方案。

### 运筹学与强化学习的深度融合

运筹学为交通问题提供了严谨的数学建模框架和优化理论,而强化学习则擅长在动态、不确定环境中学习最优策略。两者的结合通常表现为:运筹学模型为RL 提供结构化的问题定义、状态空间和动作空间设计,甚至作为RL的奖励函数或约束条件;而RL则通过学习来解决运筹学模型中难以处理的动态性、随机性和大规模计算问题。

Neria & Tzur (2024) 在解决动态取货和分配问题时,明确提出了运筹学与机器学习(包括强化学习)的新颖结合。他们将问题建模为随机动态路径和资源分配问题,并提出了一个马尔可夫决策过程(MDP)公式,这本身就是运筹学在动态规划中的经典应用。然而,由于维度灾难,直接求解MDP变得不切实际。为此,他们开发了一个启发式框架,其中大规模邻域搜索(LNS)作为运筹学启发式算法的一部分,用于探索可能的决策,而神经网络(NN)模型则通过强化学习进行训练,以近似给定状态和动作的未来价值。这种方法利用LNS的局部搜索能力和NN的函数逼近能力,有效解决了大规模动态组合优化问题,展示了运筹学在问题结构化和RL 在学习复杂价值函数方面的协同作用。

Tresca et al. (2025) 在Robo-taxi 车队协调问题中,也展示了数学建模(运筹学)与数据驱动技术(强化学习)的结合。他们通过强化学习的视角来构建 AMoD 协调问题,并提出了一个基于图网络的框架,该框架利用了图表示学习、强化学习和经

---

## 页面 11

典运筹学工具的优势。这里的“经典运筹学工具”可能指的是在 RL 框架中嵌入的
优化子问题,或者用于评估 RL 策略的性能指标。这种融合使得系统能够更好地理
解交通网络的拓扑结构,并在大规模动态环境中实现高效的车队协调。

在车辆路径问题(VRP)中,传统的运筹学算法在处理大规模和动态 VRP时面临
计算挑战。S. Li et al. (2025)提出了一种基于深度强化学习的方法来优化异构容量
车辆路径问题(HCVRP)。他们通过DRL框架,利用Linformer 和多关系节点选
择解码器,显著提高了解决方案的质量和计算效率。这代表了RL作为一种学习型
启发式方法,能够超越传统运筹学启发式算法,在复杂VRP中生成更优的解。
DRL 在这里扮演了“学习如何优化”的角色,通过大量的试错和奖励反馈,发现
传统算法难以捕捉的模式和策略。

此外,在自行车共享系统的再平衡操作中,J. Liu et al. (2024) 提出的数据驱动优化
框架也体现了这种融合。他们首先使用深度学习预测器来预测需求,然后基于这些
预测,通过序列模拟估计需求损失,以确定最优的再平衡数量。最后,他们构建了
一个混合整数线性规划(MILP)模型来优化再平衡车辆的路径问题,并提出了一
个数据驱动的分解算法来解决大规模多车辆路径问题。这个端到端解决方案清晰地
展示了深度学习在预测和运筹学在优化决策中的互补作用,其中MILP是运筹学的
核心工具。

大模型与强化学习的协同潜力

大规模语言模型(LLMs)和强化学习(RL)虽然在应用场景上有所不同,但它们之间存在着巨大的协同潜力,尤其是在处理复杂、开放式和情境感知的交通问题时。LLMs 可以作为 RL 智能体的高级“大脑”,提供情境理解、常识推理和规划能力,而RL则负责将这些高层次的规划转化为具体的行动并进行实时调整。

Liu et al. (2025)提出的MobiVerse 框架,正是这种协同的早期探索。该框架通过结合轻量级领域特定生成器和大规模语言模型来扩展城市出行模拟。LLMs 在这里的作用是进行“情境感知修改”,使得模拟中的智能体能够更真实地响应环境反馈,如道路封闭、大型集会和拥堵。这意味着LLMs可以为RL智能体提供更丰富的环境信息和更高级的决策上下文,帮助RL智能体更好地理解当前状态并生成更合理的行动。例如,LLMs可以根据文本描述的交通事件(如“前方发生交通事故,道路封闭”)生成对智能体行为的宏观指导(如“避免该区域”),然后RL智能体再根据这些指导进行具体的路径规划和驾驶决策。

Khalil et al. (2024)的综述也展望了LLMs在ITS中的潜在应用,包括交通流预测、车辆检测和分类等。如果将这些LLMs的能力与RL结合,可以想象一个场景:LLMs 分析实时交通报告和社交媒体信息,预测未来交通趋势和潜在事件,并将这些高级预测作为RL智能体的额外状态信息或奖励信号。例如,LLMs可以识别出某个区域即将举行大型活动,预测该区域将出现严重拥堵,并将此信息传递给交通信号控制的RL智能体,促使其提前调整信号配时以缓解预期拥堵。

---

## 页面 12

境感知和决策支持提供了新的工具,能够处理和分析海量的非结构化交通数据,从
而更精准地理解交通参与者的意图和行为模式。强化学习则通过智能体与环境的交
互学习,能够在复杂动态的交通环境中自主优化决策策略,实现交通信号控制、车
队调度、自动驾驶等任务的实时自适应管理。而运筹学作为优化决策的科学,为交
通问题的数学建模、算法设计和性能评估提供了坚实的基础,其与机器学习和强化
学习的结合,能够有效弥补单一方法在处理大规模、动态和不确定性问题时的不足,
实现理论与实践的深度融合。

本文旨在对基于大模型、强化学习与运筹学的城市交通研究进行全面的文献综述。
我们将系统梳理这些技术在城市交通领域的应用现状、主要贡献、面临的挑战以及
未来的发展趋势。通过对现有文献的深入分析和比较,本文旨在为研究人员和实践
者提供一个清晰的图景,以期推动城市交通研究向更智能、高效和可持续的方向发
展。本综述将首先介绍大规模语言模型在城市交通中的新兴应用,随后详细探讨强
化学习在智能交通系统中的核心作用,接着阐述运筹学方法及其与机器学习/强化
学习的融合,最后总结主要发现并展望未来研究方向。

1. 大规模语言模型在城市交通研究中的新兴应用

大规模语言模型(LLMs)作为人工智能领域近年来最引人注目的进展之一,以其卓越的自然语言理解、生成和推理能力,正在逐步渗透到各个应用领域。在城市交通研究中,LLMs的引入为处理复杂的非结构化数据、模拟人类行为以及提供情境感知决策支持开辟了新的途径。传统的交通模型往往依赖于结构化数据和预设规则,难以捕捉交通参与者行为的细微差别和外部环境的动态影响。LLMs的出现,为弥补这些不足提供了强大的工具。

Khalil et al. (2024)对深度学习(DL)在智能交通系统(ITS)中的应用进行了全面的调查,并特别探讨了LLMs在ITS中的潜在应用。该研究指出,LLMs有望在交通流预测、车辆检测与分类、路况监测、交通标志识别以及自动驾驶等多个方面发挥作用。例如,LLMs可以通过分析社交媒体数据、新闻报道和用户反馈等非结构化文本信息,识别潜在的交通事件、预测特殊事件(如大型集会、节假日)对交通流的影响,从而提供更具前瞻性的交通管理策略。此外,LLMs还能辅助生成更自然、更符合人类驾驶习惯的自动驾驶指令,提升人机交互的流畅性和安全性。该综述强调了LLMs在处理复杂时空动态、创建通用表示以及应对外部因素(如社会事件、天气)影响方面的潜力,同时也指出了未来研究面临的挑战,包括迁移学习、混合模型、隐私与安全以及超可靠低延迟通信等关键问题。这表明LLMs不仅可以作为独立的分析工具,更可以与其他先进学习技术结合,形成更强大的智能交通解决方案。

在具体的应用场景中,Liu et al. (2025)提出了MobiVerse 框架,这是一个混合框架,旨在通过结合轻量级领域特定生成器和大规模语言模型来扩展城市出行模拟的规模。该研究认识到,理解和建模人类出行模式对于有效的交通规划和城市发展至关重要,但传统的基于活动模型需要大量数据收集和手动校准,而纯粹的机器学习方法难以

---

## 页面 13

此外,LLMs还可以帮助解决RL中的奖励函数设计难题。在复杂的交通场景中, 设计一个能够准确反映多目标优化(如效率、安全、公平性)的奖励函数非常困难。 LLMs可以根据人类专家的自然语言描述,辅助生成或优化奖励函数,甚至通过与环境的交互,理解人类的偏好,从而指导 RL 智能体学习更符合人类期望的策略。

## 三者融合的未来展望

将运筹学、强化学习和大规模语言模型三者深度融合,有望构建出下一代智能交通系统。这种融合可能体现在以下几个层面:

(1) **LLMs 作为高级规划器, OR 作为精确优化器, RL 作为实时执行器:** LLMs可以根据宏观情境和历史数据,生成高层次的交通管理策略或出行建议(例如,在某个区域实施拥堵收费,或建议特定时间段内使用公共交通)。运筹学模型可以对这些策略进行精确的离线优化和评估,确保其在理论上的可行性和最优性。而强化学习智能体则负责在实时动态环境中执行这些策略,并根据实际交通状况进行微调和自适应调整。

(2) **LLMs 增强 RL 的状态表示和奖励设计:** LLMs可以处理非结构化的文本信息(如天气预报、新闻事件、用户反馈),将其转化为RL智能体可理解的结构化特征,从而丰富状态空间。同时,LLMs可以帮助设计更复杂、更符合人类直觉的奖励函数,甚至通过自然语言与人类专家交互来学习奖励偏好。

(3) **OR 为 RL 提供约束和先验知识:** 运筹学模型可以为RL智能体提供硬性约束(如车辆容量、时间窗、交通规则)和软性约束,确保RL学习到的策略是可行且符合规范的。此外,运筹学中的启发式算法可以作为RL的初始化策略或探索策略,加速 RL 的收敛。

(4) **LLMs 辅助 OR 模型构建与求解:** LLMs可以帮助理解和解析复杂的交通问题描述,自动构建或参数化运筹学模型。例如,从自然语言描述中提取约束条件、目标函数和决策变量。在求解过程中,LLMs也可以辅助解释优化结果,或生成针对特定场景的优化建议。

这种三者融合的范式,将能够更好地应对城市交通的复杂性、动态性和不确定性,实现从宏观规划到微观控制的全链条智能化。然而,这种融合也带来了新的挑战,包括如何有效整合不同模态的信息、如何平衡计算效率与模型精度、如何确保系统的可解释性和安全性,以及如何处理数据隐私和伦理问题。未来的研究需要深入探索这些挑战,并开发创新的方法和框架,以充分释放三者融合的巨大潜力。

## 智能交通系统(ITS)架构与使能技术

智能交通系统(ITS)是利用先进的信息技术、数据通信传输技术、电子传感技术、控制技术及计算机技术,对交通运输进行管理的服务系统。其目标是提高交通效率、保障交通安全、减少环境污染和改善出行体验。在基于大模型、强化学习和运筹学的城市交通研究背景下,ITS的架构和使能技术扮演着至关重要的角色,为这些先进算法的部署和运行提供了基础支撑。

---

## 页面 14

物联网 (IoT) 与车联网 (VANETs)

物联网(IoT)技术通过部署传感器、摄像头、RFID等设备,实时采集交通流、车
辆位置、环境状况等海量数据,为ITS的智能决策提供了数据基础。Dui et al.
(2024)强调了先进物联网技术对提升智能交通系统智能化水平和促进城市交通可持
续发展的深远影响。他们提出了一种基于物联网的前瞻性交通控制模型,以增强道
路感知和交通系统响应能力。当发生交通拥堵事件时,ITS可以从宏观角度为车联
网(V2X)支持的车辆提供最优控制策略,以全局控制交通流并提高交通效率。该
模型特别考虑了拥堵传播可能导致的潜在拥堵路段,并探讨了V2X支持车辆的路
径选择行为对系统性能的影响。仿真结果表明,通过控制车辆,最优控制策略能有
效缓解拥堵并显著提升交通系统性能。这表明IoT是数据采集的基石,而V2X作
为一种特殊的IoT应用,为车辆之间的通信和车辆与基础设施之间的通信提供了可
能,从而实现更精细化的交通管理和控制。

车联网(VANETs)作为一种特殊的移动自组织网络,允许车辆之间(V2V)、车
辆与基础设施之间(V2I)以及车辆与行人之间(V2P)进行实时通信。这种通信
能力对于实现协同式 ITS至关重要,尤其是在支持强化学习和运筹学算法的实时决
策方面。Ramesh et al. (2025)提出了一种先进框架,将深度强化迁移学习
(DRTL)、车联网(VANETs)和可解释人工智能(XAI)相结合,以增强智慧
城市中的智能交通系统。他们指出,现有交通管理策略难以适应快速变化的城市交
通条件,因为它们依赖于静态、基于规则的系统。该研究旨在开发一个可解释和适
应性强的ITS模型,能够学习并将知识应用于各种交通场景。DRTL模型通过利用
预训练的RL技术加速复杂城市环境中的学习,而XAI则增强了模型的可解释性,
确保 ITS操作的透明度和可靠性。通过仿真和真实世界交通数据验证,该方法在事
件检测、路线优化和拥堵预测方面取得了显著改进,证明了VANETs 在提供实时
数据和支持先进AI算法(如DRTL)以提升交通安全和效率方面的关键作用。

数据驱动与仿真平台

ITS的有效运行离不开大规模、高质量的数据支持。数据驱动的方法是当前交通研究的主流,它利用机器学习技术从海量数据中挖掘模式、预测趋势并辅助决策。

Du et al. (2025) 在建模地铁乘客路径选择时,提出了一种新颖的数据驱动方法,利用完全可微分的基于模拟的优化(SBO)框架来校准模型。该框架整合了智能卡数据和列车载荷等多源数据,以校准最能匹配观测数据的路径选择参数。这种方法强调了数据在校准复杂交通模型中的核心作用,并利用了现代机器学习的自动微分能力来提高校准效率。

仿真平台,如 SUMO (Simulation of Urban Mobility),为研究者提供了一个安全、可控的环境来测试和验证新的交通管理策略和算法,而无需在真实世界中承担风险。

Han et al. (2022) 和 Voronovskyi & Yurchak (2025) 在研究交通信号控制时,都广泛使用了SUMO仿真软件来评估他们提出的基于深度强化学习的方法。SUMO能够模拟复杂的交通流、车辆行为和信号控制,为RL智能体的训练和评估提供了逼真的环境。

---

## 页面 15

Liu et al. (2025)提出的MobiVerse 框架,本身就是一个旨在扩展城市出行模拟的混合框架,它结合了领域特定生成器和LLMs,能够高效地为大规模人口生成和动态调整日程。这种仿真平台不仅支持算法开发和策略实施,还能进行全面的评估,是连接理论研究与实际应用的重要桥梁。

## 可解释人工智能(XAI)与隐私安全

随着AI模型在ITS中扮演越来越重要的角色,模型的可解释性(XAI)和数据隐私安全问题日益突出。特别是在交通决策中,理解AI模型做出特定决策的原因对于建立信任、确保安全和满足监管要求至关重要。

Ramesh et al. (2025)的研究明确将可解释人工智能(XAI)纳入其框架,旨在增强模型的可解释性,确保ITS操作的透明度和可靠性。这表明在将DRL等复杂AI技术应用于ITS时,研究者已经开始关注如何使这些“黑箱”模型变得更透明、更易于理解。XAI技术可以帮助交通管理者理解为什么AI系统会建议某个特定的信号配时方案或路线,从而更好地评估其合理性和潜在风险。

Dong et al. (2023)在研究多智能体强化学习(MARL)用于电动汽车V2G集成时,强调了在执行阶段,模型不要求电动汽车与中心实体通信,从而确保了模型的完整性并保护了电动汽车的私人信息。这突显了在ITS中处理分布式智能体时,隐私保护是一个关键考量。随着V2X技术和共享出行服务的普及,车辆位置、出行习惯等个人数据的大量收集和处理,使得隐私保护成为ITS发展中不可忽视的伦理和技术挑战。

Khalil et al. (2024)的综述也明确将隐私和安全列为未来 ITS 发展面临的关键挑战之一。这包括如何保护交通数据的敏感性、防止网络攻击对 ITS 的干扰,以及在利用大数据和 AI 技术的同时,确保个人隐私不被侵犯。

## 总结

ITS 架构和使能技术为基于大模型、强化学习和运筹学的城市交通研究提供了坚实的基础。物联网和车联网提供了实时、海量的数据,为算法的感知和决策提供了输入;数据驱动的方法和仿真平台加速了算法的开发和验证;而可解释人工智能和隐私安全则确保了这些先进技术在实际部署中的可靠性、透明度和伦理合规性。未来的ITS 将是一个高度集成、智能协同的系统,其中各种先进技术将共同作用,以实现城市交通的可持续发展。

## 结论

本综述系统地审视了基于大规模语言模型(LLMs)、强化学习(RL)与运筹学(OR)在城市交通研究中的最新进展,揭示了这些前沿技术如何协同作用以应对日益复杂的城市交通挑战。通过对现有文献的深入分析,我们发现三者在提升交通效率、保障公平性、增强系统韧性方面展现出巨大的潜力,并正在逐步构建一个更加智能、高效和可持续的城市交通系统。

---

## 页面 16

首先,运筹学作为交通研究的基石,提供了严谨的数学建模框架和优化理论,尤其在静态规划、资源分配和车辆路径问题(如 J. Liu et al. (2024)的自行车共享再平衡优化,以及 S. Li et al. (2025)的异构容量车辆路径问题)中发挥着不可替代的作用。然而,面对城市交通的动态性和不确定性,传统运筹学方法在计算效率和适应性方面存在局限。

其次,强化学习以其在动态、不确定环境中学习最优策略的能力,在城市交通的实时决策和控制方面取得了显著突破。从交通信号控制(如 Han et al. (2022)考虑行人行为的DRL方法,以及 Voronovskyi & Yurchak (2025) 基于Q-Learning 和 DQL的交通灯控制),到车队管理与调度(如Tresca et al. (2025)的Robo-taxi 车队协调,以及 Liang (2024) 关注公平性的网约车匹配),再到交通模式分类(如 Taherinavid et al. (2024) 基于DRL的智能手机传感器模式分类)和交通流预测(如M. Li et al. (2025)对RL在TFP中应用的综述),RL展现了强大的自适应和优化能力。多智能体强化学习(MARL)进一步扩展了RL在协同决策中的应用,例如 Dong et al. (2023) 在电动汽车V2G集成中的应用。

第三,大规模语言模型作为新兴技术,在宏观出行行为模拟和情境感知方面展现出独特优势。Liu et al. (2025) 提出的MobiVerse 框架,通过结合LLMs和领域特定生成器,实现了大城市出行模拟中智能体的情境感知修改,为交通规划和政策评估提供了更真实的模拟平台。Khalil et al. (2024)的综述也展望了 LLMs 在交通流预测、车辆检测和自动驾驶等ITS领域的广阔应用前景。LLMs的自然语言理解和生成能力,有望为交通系统提供更高级别的语义理解和智能交互。

更重要的是,本综述强调了运筹学、强化学习和大规模语言模型之间的深度融合趋势。Neria & Tzur (2024)的动态取货和分配问题研究,通过将运筹学中的MDP建模与RL训练的神经网络相结合,有效克服了维度灾难。Tresca et al. (2025) 在Robo-taxi 车队协调中,也联合了数学建模、图表示学习和强化学习。这种融合范式旨在结合三者的长处:运筹学提供结构化的优化框架和理论基础;强化学习处理动态性和不确定性,学习最优策略;而大规模语言模型则提供高级情境理解、行为模拟和智能交互能力。这种协同作用有望构建出更具鲁棒性、适应性和智能化的城市交通解决方案。

尽管取得了显著进展,当前研究仍面临诸多挑战和研究缺口:(1)数据依赖与泛化能力: LLMs和DRL模型通常需要大量高质量数据进行训练,但交通数据往往存在异构性、缺失性和隐私问题。如何提高模型在数据稀疏或分布变化环境下的泛化能力,以及如何进行有效的迁移学习(如Ramesh et al. (2025)提出的DRTL)是关键。(2)模型可解释性与安全性:深度学习和LLMs的“黑箱”特性使其决策过程难以解释,这在对安全性要求极高的交通领域是一个严重问题。Ramesh et al. (2025)强调了可解释人工智能(XAI)的重要性,未来需要更多研究来提升复杂模型的透明度和可信度。(3)计算复杂性与实时性:大规模模型和多智能体强化学习的训练和推理计算成本高昂,难以满足实时交通决策的需求。开发轻量级模型、高效算法和分布式计算框架是未来的重要方向。(4)多目标优化与公平性:城市交通管理往往涉及效率、安全、公平、环境等多目标优化。如何设计有效的奖励函

---

## 页面 17

数和优化目标,以平衡不同利益相关者的需求,特别是保障公平性(如 Liang (2024) 对司机收入公平性的考量),仍需深入研究。(5) **真实世界部署与伦理隐私**: 将实验室成果推广到真实世界面临工程、法规和伦理挑战。数据隐私(如 Dong et al. (2023) 强调的隐私保护)和安全问题(如 Khalil et al. (2024) 提出的隐私和安全挑战)在 ITS 中尤为突出。

展望未来,城市交通研究将朝着以下几个方向发展:(1) **深度融合与协同智能**: 进一步探索 LLMs、RL 和 OR 的深度融合机制,构建能够进行宏观规划、中观调度和微观控制的全链条协同智能系统。例如,LLMs 作为高级规划器,OR 进行精确优化,RL 进行实时执行和自适应调整。(2) **多模态数据融合与情境感知**: 结合来自 IoT 传感器(如 Dui et al. (2024) 强调的 IoT 使能)、V2X 通信(如 Ramesh et al. (2025) 的 VANETs 应用)、社交媒体和 LLMs 处理的非结构化文本等多种模态数据,构建更全面、更精细的情境感知能力。(3) **可解释与鲁棒性 AI**: 开发具有更高可解释性、鲁棒性和抗攻击能力的 AI 模型,确保智能交通系统在复杂多变环境中的安全可靠运行。(4) **人机协同与以人为本**: 将人类专家知识和偏好融入 AI 决策过程,实现人机协同的交通管理,并更加关注出行者的个性化需求和公平性体验。(5) **数字孪生与大规模仿真**: 利用数字孪生技术构建高保真度的城市交通虚拟环境,结合 LLMs 驱动的大规模智能体仿真(如 Liu et al. (2025) 的 MobiVerse),为新策略的测试和评估提供更真实、更高效的平台。

通过持续的跨学科研究和技术创新,我们有理由相信,基于大模型、强化学习与运筹学的城市交通研究将为构建更加智能、高效、公平和可持续的未来城市交通系统贡献关键力量。

## 文献综述 3

# 基于大模型、强化学习与运筹学的城市交通研究

### 摘要

随着城市化进程的加速和智能交通系统(ITS)的蓬勃发展,城市交通面临着前所未有的复杂挑战,包括交通拥堵、环境污染、能源消耗以及效率低下等问题。传统的交通管理和优化方法往往难以适应动态变化的交通环境和多目标优化需求。近年来,大规模语言模型(LLMs)、强化学习(RL)和运筹学(OR)作为前沿技术,为解决这些复杂问题提供了新的视角和强大的工具。本综述旨在深入探讨这三种技术在城市交通研究中的应用、融合与未来发展。我们首先概述了城市交通研究的背景与挑战,随后系统性地回顾了基于强化学习的交通调度与管理、物流与能源优化、以及基于大模型的交通行为仿真等方面的最新进展。特别地,我们分析了多智能体强化学习在车队协调、信号控制和公共交通优化中的应用,并讨论了其在处理异步性、公平性及安全性方面的创新。此外,本综述还探讨了运筹学在问题建模中的基础作用,以及大模型在提升仿真精度和行为真实性方面的潜力。最后,我们总结了

---

## 页面 18

当前研究的主要发现,指出了现有方法的局限性,并展望了未来研究方向,强调了
跨学科融合在构建更智能、高效、可持续的城市交通系统中的关键作用。

**关键词:** 大规模语言模型 (LLMs)、强化学习、运筹学、智能交通系统

# 引言

城市交通系统是现代社会经济运行的动脉,其效率与可持续性直接关系到居民的生活质量和城市的竞争力。然而,伴随着人口增长、机动车保有量激增以及城市空间结构的复杂化,城市交通系统正面临着日益严峻的挑战。交通拥堵不仅导致通勤时间延长、能源消耗增加和空气污染加剧,还严重影响了经济活动和居民福祉。为了应对这些挑战,智能交通系统(ITS)应运而生,旨在通过先进的信息、通信和控制技术,提升交通系统的安全性、效率和环境友好性。传统的ITS 解决方案通常依赖于预设规则、启发式算法或基于模型的优化方法,这些方法在处理高度动态、不确定且大规模的城市交通系统时,往往暴露出适应性差、实时性不足和优化能力有限等局限性。

近年来,人工智能领域的飞速发展,特别是强化学习(Reinforcement Learning, RL)和大规模语言模型(Large Language Models, LLMs)的崛起,为城市交通研究带来了革命性的变革。强化学习以其在复杂决策任务中通过与环境交互学习最优策略的能力,在交通信号控制、车队调度、路径规划等多个方面展现出巨大潜力。它能够处理交通流的动态性、多智能体间的复杂交互以及多目标优化问题,从而实现更精细、更实时的交通管理。与此同时,运筹学(Operations Research, OR)作为一门经典的优化科学,为交通问题的数学建模和算法设计提供了坚实的基础。许多复杂的交通优化问题,如车辆路径规划(VRP)、资源分配等,本质上都是运筹学问题,而强化学习的引入则为解决这些大规模、动态的运筹学问题提供了新的范式。

大规模语言模型,作为人工智能领域的最新突破,以其强大的自然语言理解、生成和推理能力,正在逐步渗透到各个应用领域。尽管其在交通领域的直接应用尚处于早期阶段,但其在模拟人类行为、生成复杂场景、辅助决策支持以及作为智能体行为生成器等方面的潜力,预示着其在未来智能交通系统中的广阔前景。例如,LLMs 可以用于模拟驾驶员和乘客的复杂行为模式,从而提高交通仿真模型的真实性和预测精度。

本文献综述旨在全面审视基于大模型、强化学习与运筹学在城市交通研究中的最新进展。我们将系统地梳理这些技术如何被应用于解决城市交通中的关键问题,包括但不限于交通调度、车队管理、公共交通优化、电动汽车充电以及交通流预测等。通过对现有文献的深入分析,我们将揭示不同方法之间的联系与区别,评估其优劣,并探讨它们在实际应用中面临的挑战和未来的发展方向。本综述将特别关注这些技术如何协同工作,以期为构建更加智能、高效和可持续的未来城市交通系统提供理论基础和实践指导。

---

## 页面 19

# 强化学习在城市交通调度与管理中的应用

强化学习(RL)以其在复杂、动态环境中通过试错学习最优策略的独特优势,已成为解决城市交通调度与管理问题的强大工具。从交通信号控制到自动驾驶车队协调,再到网约车匹配和公共交通优化,RL的应用范围日益广泛,并展现出超越传统方法的优越性能。

## 智能交通信号控制

交通信号控制是城市交通管理的核心环节之一,其目标在于优化交叉口通行效率,减少车辆和行人的等待时间,从而缓解交通拥堵。传统的信号控制方法通常基于固定配时、感应控制或协调控制,难以适应交通流的实时波动和突发事件。深度强化学习(DRL)的引入为这一领域带来了革命性的变革,使其能够根据实时的交通状态动态调整信号配时。

Han et al. (2022)提出了一种考虑行人行为的深度强化学习交通信号控制方法。该研究指出,大多数信号控制优化方法通常以最大化交通容量为目标,却忽视了交叉口行人的需求。为了解决这一问题,他们的方法将强化学习网络与交通信号控制策略相结合,同时考虑了交通效率和安全性,并将行人和车辆通过交叉口的等待时间纳入优化目标。通过改进离散交通状态编码(Discrete Traffic State Encoding, DTSE)方法,该研究定义了更全面的状态和奖励函数,以捕捉复杂的交通情景。在神经网络训练方面,他们采用了多进程操作方法,同时运行多个环境进行训练,显著提高了模型的训练效率。在SUMO仿真软件中对实际交叉口场景进行的广泛实验表明,与Dueling DQN等传统方法相比,他们的方法将等待时间减少了58.76%,等待人数减少了51.54%,有效降低了交叉口行人和车辆的等待时间和等待人数。这表明,将行人因素纳入DRL信号控制的优化目标,不仅能提升交通效率,还能显著改善行人的出行体验和安全性,为构建更人性化的智能交通系统提供了重要思路。

与此类似,Voronovskyi & Yurchak (2025)也深入分析了智能交通系统(ITS)中优化城市交通的现代方法,并特别关注了在动态道路交通条件下用于控制交通信号的无模型强化学习算法,如Q-Learning 和 Deep Q-Learning。该研究通过在SUMO环境中的仿真结果证明,实施这些算法能够显著减少交叉口排队并提高交通网络的容量。尤其值得注意的是,Deep Q-Learning 的应用使得系统能够更有效地处理来自物联网(IoT)传感器和V2X(Vehicle-to-Everything)技术的大量数据,从而实现对不断变化的交通状况的更真实适应。这篇文献强调了深度神经网络和多智能体方法在未来研究中的潜力,认为它们将进一步改善城市环境中的交通管理结果,并为创建“智能”交通基础设施奠定基础。这与Han et al. (2022)的工作形成呼应,共同强调了DRL在处理复杂交通数据和动态环境中的优越性,并指出了多智能体方法在未来交通信号控制中的重要性。

然而,交通信号控制的复杂性不仅在于动态调整信号配时,还在于处理非信号交叉口以及大规模多智能体环境下的协调问题。K. Wang et al. (2024)针对非信号交叉口大规模自动驾驶车辆(AVs)的换道决策问题,提出了一种名为AF-DQN

---

## 页面 20

(Action Filter-based Deep Q-Network)的方法。该研究指出,虽然自动驾驶技术备受关注,但仅依靠单一自动驾驶车辆不足以满足未来交通系统的需求,连接式自动驾驶车辆(CAVs)的运行依赖于多智能体决策技术。非信号交叉口因其高交通量、复杂交互和显著风险而成为研究重点。AF-DQN通过引入动作过滤器,使AVs能够有效过滤掉潜在危险的换道动作并执行安全动作。此外,该研究设计了一个考虑安全性、任务完成度和合规性等多因素的多目标奖励函数。为了提高训练效率,还引入了一种探索性训练策略,使智能体能够先在简单场景中通过探索学习,再解决复杂场景中的驾驶任务。实验结果验证了所提方法的有效性和优越性,表明探索性训练加速了模型训练速度并提高了训练效果,AF-DQN在安全性、效率和遵守交通规则方面均优于基线方法。这篇文献不仅展示了DRL在复杂决策场景中的应用,还通过动作过滤和探索性训练策略解决了实际应用中的安全性和训练效率问题,为未来自动驾驶车辆在复杂交叉口环境中的安全高效运行提供了重要保障。

综合来看,DRL 在交通信号控制领域取得了显著进展,能够有效应对动态交通流、行人需求和复杂交互。未来的研究方向可能包括更精细的状态表示、更鲁棒的奖励函数设计、多智能体间的协作机制以及将 LLMs 引入到交通场景理解和决策辅助中,以进一步提升控制策略的智能性和适应性。

## 自动驾驶与车队协调

随着自动驾驶技术的发展,由自动驾驶车辆组成的车队(如自动驾驶移动按需服务, AMoD 系统)有望彻底改变城市交通格局,带来减少污染、降低能耗和缓解城市拥堵等社会效益。然而,如何在大规模环境下协调这些车队,使其发挥最大潜力,仍然是一个关键挑战。

Tresca et al. (2025) 提出了一种新颖的决策框架,将数学建模与数据驱动技术相结合,以解决大规模自动驾驶出租车车队协调问题。该研究将 AMoD 协调问题视为强化学习问题,并提出了一种基于图网络(Graph Network)的框架。该框架充分利用了图表示学习、强化学习和经典运筹学工具的优势。通过在不同仿真精度和场景下的广泛评估,该方法展现出卓越的系统性能、计算效率和泛化能力,优于现有方法。更重要的是,为了促进该领域的研究民主化,该团队公开发布了网络级协调的基准、数据集和模拟器,以及一个开源代码库,旨在提供可访问的仿真平台并建立标准化验证流程以比较不同方法。这篇文献的贡献在于其综合性方法,将 RL 与图网络和 OR 工具相结合,有效解决了大规模 AMoD 系统的复杂协调问题,并为后续研究提供了宝贵的资源。其强调了图网络在处理大规模、互联互通的交通网络中的强大能力,以及 RL 在动态决策中的优势,同时不忘运筹学在问题建模和约束处理上的基础作用。

与车队协调紧密相关的是多智能体系统中的协作与决策。Liu et al. (2024)探讨了多智能体强化学习(MARL)中的主动可读性(Active Legibility)问题,这在城市交通、自动驾驶等关键应用中具有重要意义。该研究指出,MARL的解决方案范式中,对其他智能体进行建模以理解和预测其行为,从而促进协作,是一个重要的方向。受近期关于可读性研究的启发(即智能体通过其行为揭示意图),他们提出了

---

## 页面 21

一个多智能体主动可读性框架来提高性能。这个以可读性为导向的框架允许智能体执行可读性动作,从而帮助其他智能体优化其行为。通过设计一系列模拟常见场景并能最好地表征 MARL 中可读性的问题域,实验结果表明,与几种多智能体强化学习算法相比,新框架更高效且训练时间更短。虽然这篇文献没有直接应用于具体的城市交通场景,但其提出的主动可读性框架对于自动驾驶车队协调、交叉口决策等需要多智能体协作的交通问题具有重要的理论指导意义。在AMoD系统中,如果车辆能够通过“可读”的行为向其他车辆或交通系统表达其意图,将极大提升系统的整体效率和安全性。例如,一辆自动驾驶出租车在接近交叉口时,其减速或变道行为如果能清晰地传达其意图,将有助于其他车辆或交通信号系统做出更优的决策。

这些研究共同揭示了强化学习在自动驾驶和车队协调中的巨大潜力。未来的研究可以进一步探索如何将 LLMs 的场景理解和行为生成能力融入到 MARL 框架中,以实现更高级别的智能体交互和决策,例如,LLMs 可以帮助智能体理解复杂的交通规则和人类驾驶员的非语言信号,从而做出更符合实际情况的决策。

## 网约车与共享出行

网约车和共享出行服务已成为现代城市交通的重要组成部分,其核心挑战在于如何设计合理的算法来匹配司机和乘客,同时优化多重目标,如平台总收入、乘客等待时间以及司机收入公平性等。

Liang (2024) 深入探讨了网约车匹配问题,并提出了一种公平性导向的动态网约车匹配算法。该研究指出,网约车匹配问题受到天气、交通和供需动态等多种现实世界约束的影响,需要优化平台总收入和乘客等待时间等多个目标,其复杂性使其成为移动交通领域的核心问题。然而,现有研究普遍缺乏对司机收入公平性的探索,且部分算法在工业环境中缺乏实际适用性。为弥补这些不足,该研究开发了一种公平性导向的动态匹配算法,有效优化了平台整体效率(预期司机总收入)和司机间的收入公平性(加权摊销公平性信息熵)。首先,该研究在场景设置中引入了匹配结果对后续匹配的时间依赖性,并利用强化学习预测这些时间依赖性,克服了传统匹配算法仅依赖历史数据和当前情况进行订单分配的局限性。其次,通过引入时间窗匹配模型、剪枝操作和度量表示调整等一系列优化方案,增强了算法对大规模数据集的适应性和可扩展性,同时确保了算法的效率。最后,在真实数据集上进行的实验表明,该基于强化学习的公平性导向算法在公平性、平台效用和匹配效率方面分别比传统算法提高了81.4%、28.5%和79.7%。这篇文献的创新之处在于将公平性作为核心优化目标之一,并通过强化学习捕捉匹配结果的时间依赖性,这对于构建可持续发展的共享出行生态系统至关重要。它不仅关注了宏观的平台效率,也兼顾了微观的个体(司机)利益,体现了多目标优化的复杂性和RL在处理此类问题上的优势。

该研究与 Tresca et al. (2025) 在AMoD系统中的车队协调有异曲同工之妙,两者都涉及大规模车辆的调度和匹配,但Liang (2024) 更侧重于网约车场景下的公平性问题,而Tresca et al. (2025) 则更侧重于自动驾驶车队的整体效率和泛化能力。两者

---

## 页面 22

都利用了强化学习来处理动态决策和复杂交互,但具体的奖励函数设计和状态表示
有所不同。未来的研究可以探索如何将公平性考量融入 AMoD 系统的车队协调中,
以及如何利用 LLMs 来理解乘客和司机的个性化需求,从而提供更智能、更公平的
匹配服务。

公共交通优化

公共交通系统是城市可持续交通的关键组成部分,但其运营稳定性常受乘客需求和交通状况不确定性的影响。公交车“扎堆”(bus bunching)现象是常见的服务可靠性和效率下降的原因。尽管多智能体强化学习(MARL)在交通控制方面取得了进展,但由于公交车控制动作只在车辆到达站点时发生,导致智能体行动的异步性,针对公交车队控制的研究相对较少。

J. Wang & Sun (2021) 提出了一种异步多智能体强化学习 (ASMAR) 方法来解决公交车扎堆问题。该研究将线路级公交车队控制问题建模为异步多智能体强化学习问题,并扩展了经典的 Actor-Critic 架构以处理异步性。具体而言,他们设计了一种新颖的 Critic 网络,用于有效近似其他智能体的边际贡献,其中图注意力神经网络 (Graph Attention Neural Network) 被用于进行归纳学习以进行策略评估。这种 Critic 结构还有助于自我智能体更有效地优化其策略。该框架在基于智能卡数据推导的真实公交服务和实际乘客需求上进行了评估。结果表明,所提出的模型优于传统的基于车头时距的控制方法和现有的 MARL 方法。这篇文献的亮点在于其对异步性问题的创新性处理,通过设计特殊的 Critic 网络和利用图注意力机制,使得 MARL 能够有效应用于公交车队控制这一复杂场景。公交车扎堆问题本质上是一个多智能体协作问题,每辆公交车都是一个智能体,它们需要相互协调以维持稳定的车头时距。该研究为解决这类异步、分布式控制问题提供了有价值的范例。

这与 Tresca et al. (2025) 在 AMoD 车队协调中利用图网络的方法有相似之处,都强调了图结构在捕捉交通网络中智能体间关系的重要性。然而,J. Wang & Sun (2021) 更侧重于解决 MARL 中的异步性挑战,这在实际交通系统中普遍存在。未来的研究可以进一步探索如何将 LLMs 的上下文理解能力应用于公交车队控制,例如,LLMs 可以帮助系统理解乘客的实时反馈、交通事件报告,从而更智能地调整公交调度策略。

强化学习在城市物流与能源管理中的应用

除了直接的交通调度与管理,强化学习在城市物流和能源管理领域也展现出巨大的
应用潜力,尤其是在电动汽车(EV)充电优化和车辆路径规划等与城市交通紧密
相关的场景中。

电动汽车充电与 V2G

随着“双碳”政策的深入推进,电动汽车(EV)产业作为替代化石燃料的重要途径,近年来发展迅速。电动汽车快充站因其高效、快速的充电特性,在公共充电市

---

## 页面 23

适应动态条件,基于 LLMs 的智能体模拟又面临计算约束。MobiVerse 通过利用领
域特定生成器高效生成基础活动链,并结合 LLMs 进行情境感知修改,有效解决了
这些挑战。例如,在洛杉矶韦斯特伍德的案例研究中,MobiVerse 能够高效地为约
53,000 名居民生成并动态调整出行计划,使智能体能够响应环境反馈,如道路封闭、
大型集会活动(如足球比赛)和交通拥堵。这种混合方法不仅保持了计算效率,还
增强了行为的真实性,为出行系统规划和运营提供了一个可定制的平台。
MobiVerse 的模块化设计也促进了在交通系统和智能体层面测试各种出行算法。这
表明 LLMs 在模拟复杂人类行为、提供动态情境感知和实现大城市出行仿真方
面具有显著优势,能够弥补传统模拟方法在灵活性和真实性方面的不足。

尽管 LLMs 在城市交通领域展现出巨大潜力,但其应用仍面临诸多挑战。首先,
LLMs 的训练和推理需要巨大的计算资源,这对于实时性要求极高的交通管理系统
而言是一个显著的障碍。其次,LLMs 的“黑箱”特性使得其决策过程难以解释,
这在涉及公共安全和信任的交通领域尤为关键。如何确保 LLMs 决策的透明度、可
解释性和可靠性,是未来研究需要重点关注的问题。此外,交通领域数据的多样性和复杂性(包括结构化数据、非结构化文本、图像、视频等)要求 LLMs 具备多模态处理能力,以实现更全面的情境理解。最后,数据隐私和安全问题在利用 LLMs
处理个人出行数据时也必须得到充分考虑。

总而言之,大规模语言模型为城市交通研究带来了前所未有的机遇,特别是在提升
模拟真实性、实现情境感知决策和处理非结构化数据方面。通过与传统交通模型和
机器学习方法的结合,LLMs 有望推动智能交通系统迈向更高水平的智能化和自适
应性。然而,计算效率、可解释性、多模态处理和数据隐私等挑战仍需深入研究和
解决,以充分释放 LLMs 在城市交通领域的潜力。

2. 强化学习在智能交通系统中的核心作用

强化学习(RL)作为机器学习的一个重要分支,通过智能体与环境的交互,学习
如何在不确定和动态的环境中做出最优决策以最大化累积奖励。其自适应学习和决
策能力使其成为解决智能交通系统(ITS)中复杂动态问题的理想工具。RL在交通
流管理、信号控制、共享出行调度、自动驾驶决策以及交通行为分析与预测等多个
关键领域都展现出强大的应用潜力。

2.1 交通流管理与信号控制

交通信号控制是城市交通管理的核心环节,传统的固定配时或感应控制方法难以适
应实时变化的交通状况。强化学习通过将交通信号控制器视为智能体,将交通状态
(如车流量、排队长度)作为环境状态,将信号配时方案作为动作,通过最大化交
通效率(如最小化车辆等待时间、最大化通行能力)来学习最优控制策略。

Han et al. (2022)提出了一种考虑行人行为的深度强化学习交通信号控制方法。该研究认识到,大多数信号控制优化仅以最大化交通容量为目标,而忽略了交叉口行人的需求。为了解决这一问题,他们将强化学习网络与交通信号控制策略相结合,

---

## 页面 24

场中占据重要地位。然而,快充站带来的高随机性和快速增长的充电负荷,对电网
的安全稳定运行构成了严峻挑战。

Jia et al. (2024) 提出了一种基于深度强化学习 DQN (Deep Q-Network)算法的城市
变电站充电站优化配置方法。该研究旨在通过分析站内分布式电源的输出特性和电
动汽车的充电行为模式,以经济和运行效率为基础,优化各充电站的容量,并构建
一个典型的快充站优化运行配置模型。该模型不仅受到站内功率平衡和分布式电源
输出等关键因素的约束,还考虑了变电站充电配置的优化,以确保充电站的高效运
行和电网的稳定性。通过使用DQN算法替代传统的遗传优化算法求解模型的最优
解,该研究实现了充电站配置的精细化管理。最终,通过对各种配置案例的实证分
析,验证了所提方法的有效性和可行性,为城市快充站的优化运行提供了新的技术
路径和决策支持。这篇文献将DQN应用于能源管理中的资源配置问题,体现了
RL 在处理复杂约束和动态决策方面的能力,为电动汽车充电基础设施的规划和运
营提供了智能化的解决方案。

与此相关,电动汽车不仅是交通工具,还可以作为分布式能源资源(DERs)通过
车网互动(Vehicle-to-Grid, V2G)方案整合到智能电网中。公用事业公司可以利用
电动汽车电池向电网反向供电,以削减峰值负荷。然而,高效地将电动汽车整合到
电网中需要精确的人工智能机制来预测、协调和调度电动汽车。

Dong et al. (2023) 提出了一种多智能体强化学习(MARL)机制,用于调度电动汽
车电池的日前放电过程,以优化电网的削峰性能。该研究指出,电动汽车是未来智
能交通系统(ITS)的支柱,它们不仅环保,还可以通过V2G方案作为分布式能源
资源整合到智能电网中。所提出的MARL克服了能源预测的不准确性,通过允许
智能体(即电动汽车)做出自主决策。这些智能体以集中式方式进行训练,但在执
行阶段进行本地决策,以保持自主性和隐私性。特别地,该模型在执行阶段不需要
电动汽车与中央实体进行通信,这保证了模型的完整性并保护了电动汽车的私人信
息。通过一系列全面的实验,验证了MARL协调和调度机制的有效性,并表明该
模型确实能够削平峰值负荷。这篇文献的创新之处在于其MARL框架,它解决了
V2G 集成中的预测不准确性问题,并通过分布式决策保障了用户隐私和系统完整
性。这对于未来智能电网和智能交通系统的协同发展具有重要意义。

这两篇文献共同展示了强化学习在电动汽车生态系统中的关键作用,从基础设施的
优化配置到车辆与电网的智能互动。未来的研究可以探索如何将 LLMs 的预测能力
和用户行为建模能力融入到电动汽车充电和V2G调度中,例如,LLMs可以根据
历史数据和实时信息预测用户的充电需求和出行模式,从而更精准地优化充电站配
置和V2G调度策略。

车辆路径规划

车辆路径规划问题(VRP)是城市物流和交通运输领域的核心挑战之一,旨在为一
支异构车队规划最优路线,以高效满足多样化的客户需求。传统的精确算法和启发
式算法在处理大规模问题时面临显著的计算障碍。

---

## 页面 25

S. Li et al. (2025) 针对异构容量车辆路径问题(HCVRP)提出了一种新的深度强化学习(DRL)方法。HCVRP 在城市杂货配送中提出了关键挑战,需要优化具有不同容量和速度的异构车队的路线,以高效满足多样化的客户需求。为了解决这些挑战,该研究引入了一种新的神经网络架构,其中包含了专门为HCVRP量身定制的先进注意力机制。该方法具有两项主要创新:(1)引入Linformer,以大幅降低计算需求;(2)设计多关系节点选择解码器,以提高决策过程的准确性和效率。通过广泛的实验,该DRL框架在各种问题规模和目标下,始终超越传统启发式算法和现有 DRL 模型,提供卓越的解决方案质量和计算效率。这项研究强调了集成尖端机器学习技术在改进和加速复杂运输和物流操作解决方案方面的变革潜力。这篇文献成功地将DRL与先进的注意力机制(如Linformer)相结合,有效解决了大规模HCVRP问题,展示了DRL在复杂组合优化问题中的强大能力。它不仅提升了解决方案的质量,也显著提高了计算效率,这对于实时物流调度至关重要。

该研究与 Tresca et al. (2025) 在AMoD 车队协调中利用图网络和OR工具的方法有共通之处,两者都致力于解决大规模车队调度和路径优化问题。然而,S. Li et al. (2025) 更侧重于异构车队和多目标优化下的路径规划,而Tresca et al. (2025) 则更侧重于自动驾驶车队的实时协调。两者都体现了RL在处理复杂运筹学问题上的优势。未来的研究可以探索如何将 LLMs的语义理解能力应用于VRP,例如,LLMs可以帮助系统理解客户的特殊配送要求、交通限制的自然语言描述,从而生成更符合实际需求的路径规划方案。

## 大模型与混合仿真在城市交通研究中的新兴作用

大规模语言模型(LLMs)以其强大的自然语言处理能力和复杂行为模拟潜力,正在为城市交通研究,特别是交通仿真领域,开辟新的途径。传统的交通仿真模型往往需要大量数据收集和手动校准,而基于机器学习的方法在适应动态条件时面临挑战。

Liu et al. (2025) 提出了一种名为 MobiVerse 的混合框架,旨在通过结合轻量级领域特定生成器和大规模语言模型,扩展城市出行仿真规模。该研究指出,理解和建模人类出行模式对于有效的交通规划和城市发展至关重要。尽管出行研究取得了显著进展,但在允许算法开发、政策实施和大规模综合评估的仿真平台方面仍存在关键空白。传统的基于活动模型需要大量数据收集和手动校准,机器学习方法难以适应动态条件,而新兴的基于大语言模型(LLMs)的智能体仿真在处理大规模仿真时面临计算限制。为了解决这些挑战,MobiVerse 框架利用轻量级领域特定生成器生成基础活动链的效率,并结合 LLMs 的上下文感知修改能力。该研究以洛杉矶韦斯特伍德为例进行了案例研究,在一个标准 PC 上高效生成并动态调整了约 53,000 名智能体的人口日程。实验结果表明,MobiVerse 成功地使智能体能够响应环境反馈,包括道路封闭、大型集会活动(如足球比赛)和交通拥堵,通过其混合框架实现了这一点。其模块化设计有助于在交通系统和智能体层面测试各种出行算法。结果显示,该方法在保持计算效率的同时增强了行为真实性。MobiVerse 通过提供一个可定制的出行系统规划和操作平台以及基准算法,弥合了出行仿真领域的空白。

---

## 页面 26

这篇文献的创新性在于将 LLMs 引入到大规模城市出行仿真中, 解决了传统方法在数据收集、校准和动态适应性方面的局限性。LLMs 的引入使得仿真智能体能够更真实地响应环境反馈和复杂事件, 从而提高了仿真模型的行为真实性。这种混合框架的优势在于, 它既利用了领域特定生成器的高效性来处理基础活动链, 又利用了 LLMs 的灵活性和上下文感知能力来处理复杂的、非结构化的行为修改。这对于评估新的交通政策、测试自动驾驶算法以及理解城市居民的出行行为模式具有重要意义。

MobiVerse 的出现, 预示着 LLMs 在智能交通系统中的应用将从辅助决策、信息处理等层面, 扩展到直接参与复杂系统仿真和行为生成。未来的研究可以进一步探索 LLMs 在以下方面的潜力:
1. **更精细的人类行为建模:** LLMs 可以学习和模拟更复杂的驾驶员、乘客和行人行为, 包括情绪、偏好、决策逻辑等, 从而使仿真结果更接近真实世界。
2. **情境感知与推理:** LLMs 可以处理和理解来自传感器、社交媒体等多种来源的非结构化信息, 进行情境感知和推理, 从而指导仿真智能体在突发事件(如交通事故、天气变化)中的行为。
3. **政策评估与规划:** 利用 LLMs 生成不同政策情景下的交通行为和系统响应, 辅助城市规划者评估政策效果, 优化城市布局和交通基础设施。
4. **与强化学习的融合:** LLMs 可以作为强化学习智能体的“大脑”, 提供高级别的策略指导、目标设定或环境理解, 从而加速 RL 的训练过程并提升其在复杂任务中的表现。例如, LLMs 可以帮助 RL 智能体理解交通规则的自然语言描述, 或者根据历史事件生成应对策略。

尽管 LLMs 在交通仿真中展现出巨大潜力, 但也面临计算资源消耗大、数据隐私和模型可解释性等挑战。未来的研究需要在这方面进行深入探索, 以实现 LLMs 在城市交通领域的更广泛和更负责任的应用。

# 智能交通系统中的先进学习技术与挑战

智能交通系统(ITS)的复杂性和动态性要求我们不断探索和整合先进的学习技术。除了上述具体的应用场景,一些研究从更宏观的视角审视了深度学习、强化学习乃至大规模语言模型在ITS中的应用前景、挑战和理论进展。

## 深度强化学习与迁移学习

城市交通拥堵是一个普遍存在的问题,它降低生活质量、增加污染并导致经济效率低下。传统的交通管理策略由于依赖静态、基于规则的系统,难以适应快速变化的城市交通状况。智能交通系统(ITS)运行在高度动态的环境中,其复杂的时空模式受到天气、社会事件和节假日等因素的影响。准确建模这些关系、开发通用表示并将其应用于交通挑战仍然是关键障碍。

Ramesh et al. (2025) 提出了一种先进的框架,通过整合深度强化迁移学习(DRTL)、车载自组织网络(VANETs)和可解释人工智能(XAI)来增强智慧城市中的智能交通系统。该研究旨在开发一个可解释且适应性强的ITS模型,能够学习并将知识应用于各种交通场景,以优化交通流、提高道路安全并改善决策透明。

---

## 页面 27

度。DRTL 模型通过利用预训练的RL技术加速在复杂城市环境中的学习,从而促进快速适应。XAI增强了模型的可解释性,确保了ITS操作的透明度和可靠性。所提出的方法通过仿真和真实交通数据进行验证,在事件检测、路线优化和拥堵预测方面显示出显著改进。与传统机器学习模型相比,结果显示中位数拥堵减少了35%,实时路线规划提高了40%,事故响应时间缩短了25%。这项研究通过改善车辆交互、决策准确性和系统理解,为未来智慧城市开发智能、适应性强且更安全的交通网络做出了贡献。

这篇文献的贡献在于其综合性方法,将DRTL、VANETs和XAI融合,以解决 ITS中的适应性、可解释性和实时性问题。DRTL的引入使得模型能够利用在其他交通场景中学习到的知识,加速在新环境中的学习过程,这对于应对ITS中不断变化的条件至关重要。XAI的集成则解决了深度学习模型普遍存在的“黑箱”问题,使得ITS 的决策过程更加透明和可信,这对于实际部署和公众接受度至关重要。

VANETs 则提供了实时数据传输和车辆间通信的基础。这篇文献强调了迁移学习在应对 ITS 复杂性和动态性方面的潜力,以及可解释性在提升系统可靠性和信任度方面的重要性。

## 多智能体强化学习的理论进展

多智能体强化学习(MARL)在城市交通等许多关键应用中扮演着核心角色,其解决方案近年来取得了巨大发展。其中,对其他智能体进行建模以理解和预测其行为,从而促进协作的范式引起了广泛关注。

Liu et al. (2024) 提出的主动可读性框架,正是基于这一思想的理论性探索。该研究指出,多智能体序列决策问题在城市交通、自动驾驶汽车、军事行动等许多关键应用中都有体现。其广泛已知的解决方案,即多智能体强化学习,近年来取得了巨大发展。其中,对其他智能体进行建模的解决方案范式吸引了我们的兴趣,这与传统的价值分解或通信机制不同。它使智能体能够理解和预测其他智能体的行为,并促进它们的协作。受近期关于可读性研究的启发(即智能体通过其行为揭示意图),我们提出了一个多智能体主动可读性框架来提高它们的性能。这个以可读性为导向的框架允许智能体执行可读性动作,从而帮助其他智能体优化其行为。此外,我们设计了一系列模拟常见场景并能最好地表征多智能体强化学习中可读性的问题域。实验结果表明,与几种多智能体强化学习算法相比,新框架更高效且训练时间更短。

尽管这篇文献没有直接应用于具体的城市交通场景,但其提出的主动可读性框架对于提升 MARL 在城市交通中的应用具有深远的理论意义。在自动驾驶车队协调、交通信号控制、网约车匹配等场景中,智能体之间的有效协作是实现系统整体优化的关键。如果智能体能够通过其行为清晰地表达意图,将大大减少不确定性,提高决策效率和安全性。例如,在自动驾驶车辆通过交叉口时,如果车辆能够通过其行驶轨迹、速度变化等“可读”行为向其他车辆或交通信号系统传递其意图,将有助于避免冲突,提高通行效率。这与 K. Wang et al. (2024) 在非信号交叉口通过动作过滤器确保安全决策的思路有异曲同工之妙,但Liu et al. (2024) 更侧重于通过行为本身传递信息以促进协作,而非仅仅过滤不安全动作。

---

## 页面 28

# 交通流预测

交通流预测(TFP)是运筹学和交通工程领域的重要课题,旨在预测未来特定时间段内交通网络中的人流和车流。准确的TFP对于交通管理、城市规划、道路设计和智能交通系统(ITS)的发展具有重要意义。

M. Li et al. (2025) 综述了强化学习在交通流预测中的应用,并讨论了其优势、问题和前景。该研究首先总结了三种传统的TFP方法:基于参数的预测、基于浅层机器学习的预测和基于深度学习(DL)的预测。然而,传统的TFP方法仅关注交通数据中的时间序列预测,难以捕捉交通网络中交通空间分布与各位置交通状况时间演变之间的相互依赖关系。如何充分提取交通流的时空关联性(SCTF)是基于DL预测模型亟待解决的问题。同时,随着科学技术的发展,越来越多的学者尝试将强化学习(RL)融入TFP。实验结果表明,RL能够更大程度地减少车辆排队时间和平均延误,并缓解空气污染。该文章总结了DL和RL在TFP中的模型,全面比较了各种方法的优缺点,并提出了现有问题和未来发展的愿景。

这篇文献的价值在于其对 TFP 领域现有方法的全面回顾,并特别强调了强化学习在解决传统方法局限性方面的潜力。传统方法在处理交通流的时空关联性方面存在不足,而 RL 通过与环境的交互学习,能够更好地捕捉这些复杂的动态关系。RL在 TFP 中的应用不仅能够提高预测精度,还能通过优化决策(如信号控制、路径规划)来直接改善交通状况,从而减少拥堵和污染。这与 Han et al. (2022) 和 Voronovskyi & Yurchak (2025) 在交通信号控制中利用 RL 优化交通流的思路相吻合, TFP 可以为 RL 控制提供更准确的未来状态信息,从而实现更优的决策。

# 综合性综述与未来展望

智能交通系统(ITS)运行在一个高度复杂和动态的环境中,其复杂的时空动态在不同尺度上表现出来,并受到社会事件、节假日和天气等外部因素的影响。建模这些元素之间复杂的相互作用、创建通用表示并将其应用于解决交通问题,这些都是当代 ITS 面临的多方面挑战的一部分。

Khalil et al. (2024) 提供了一份全面调查,探讨了深度学习(DL)在ITS中的应用,主要关注从业者解决这些多方面挑战的方法。该研究重点关注指导创新解决方案制定的架构和问题特定因素。除了阐明最先进的DL算法外,该研究还探讨了DL和大规模语言模型(LLMs)在ITS中的潜在应用,包括交通流预测、车辆检测和分类、道路状况监测、交通标志识别和自动驾驶车辆。此外,该研究还指出了几个未来挑战和研究方向,以推动ITS的边界,包括迁移学习、混合模型、隐私和安全以及超可靠低延迟通信等关键方面。该综述旨在弥合新兴DL和交通社区之间的鸿沟,促进对该领域挑战和可能性的更深入理解,并激发对新视角和问题的进一步探索,从而在塑造交通系统的未来中发挥关键作用。

这篇文献作为一篇综合性综述,为我们理解DL和LLMs在ITS中的广泛应用和未来发展提供了宏观视角。它不仅总结了DL在ITS中的现有成就,更前瞻性地探讨了LLMs的潜力,并指出了未来研究的关键挑战,如迁移学习、混合模型、隐私安

---

## 页面 29

全和通信延迟等。这与 Ramesh et al. (2025) 强调 DRTL 和 XAI 的重要性相呼应, 也与 Liu et al. (2025) 探索 LLMs 在交通仿真中的应用相契合。该综述为本研究提供了重要的背景和方向性指导, 强调了跨学科融合和解决实际挑战的重要性。

综合来看, 这些先进学习技术正在深刻改变 ITS 的面貌。深度强化学习提供了在复杂动态环境中学习最优策略的能力; 迁移学习和可解释 AI 则增强了模型的适应性和透明度; 多智能体强化学习的理论进展为解决智能体间协作问题提供了新思路; 而 LLMs 的引入则有望提升交通系统的行为模拟和决策支持能力。然而, 这些技术在实际部署中仍面临数据可用性、计算资源、模型鲁棒性、安全性和隐私保护等诸多挑战, 需要未来的研究持续探索和攻克。

## 结论

城市交通研究正处于一个由大规模语言模型 (LLMs)、强化学习 (RL) 和运筹学 (OR) 深度融合驱动的变革时代。本综述系统地回顾了这些前沿技术在解决城市交通复杂挑战中的最新进展, 涵盖了从宏观的交通调度与管理到微观的车辆行为决策, 再到物流优化和能源管理等多个关键领域。

在交通调度与管理方面, 强化学习展现出卓越的性能。智能交通信号控制领域, Han et al. (2022) 和 Voronovskyi & Yurchak (2025) 的研究表明, 深度强化学习能够有效优化交叉口通行效率, 显著减少车辆和行人的等待时间, 并且能够适应动态变化的交通状况。特别是 Han et al. (2022) 创新性地将行人行为纳入优化目标, 提升了交通系统的公平性和人性化。在自动驾驶与车队协调方面, Tresca et al. (2025) 提出的基于图网络和强化学习的框架, 成功解决了大规模自动驾驶出租车 (AMoD) 车队的协调问题, 并强调了运筹学在问题建模中的基础作用。Liu et al. (2024) 关于多智能体强化学习中主动可读性的理论探索, 为未来自动驾驶车队更高效、更安全的协作提供了理论基础。网约车与共享出行领域, Liang (2024) 引入了公平性考量, 通过强化学习优化司机收入公平性, 克服了传统匹配算法的局限性。公共交通优化方面, J. Wang & Sun (2021) 针对公交车“扎堆”问题, 提出了异步多智能体强化学习方法, 有效处理了智能体行动的异步性, 提升了公交服务的可靠性。这些研究共同揭示了强化学习在处理城市交通动态性、复杂交互和多目标优化方面的强大能力。

在城市物流与能源管理方面, 强化学习同样发挥着关键作用。电动汽车充电与 V2G 领域, Jia et al. (2024) 利用 DQN 算法优化城市变电站充电站的配置, 提升了经济性和运行效率。Dong et al. (2023) 则提出了多智能体强化学习机制, 实现了电动汽车电池的日前放电调度, 有效削平了电网峰值负荷, 同时保障了用户隐私和系统完整性。这些工作为构建智能电网与智能交通系统协同发展的未来奠定了基础。在车辆路径规划 (VRP) 方面, S. Li et al. (2025) 引入了深度强化学习与先进注意力机制 (如 Linformer), 成功解决了异构容量车辆路径问题 (HCVRP), 显著提升了解决方案的质量和计算效率, 为城市物流的精细化管理提供了新途径。

---

## 页面 30

大规模语言模型(LLMs)作为新兴力量,正在为城市交通研究带来新的范式。
Liu et al. (2025)提出的MobiVerse 混合框架,通过结合轻量级领域特定生成器和
LLMs,实现了大城市出行仿真,显著增强了仿真智能体的行为真实性和对环
境反馈的适应性。这预示着LLMs在模拟人类行为、生成复杂场景和辅助决策支持
方面的巨大潜力,有望弥补传统仿真模型在数据收集和动态适应性方面的不足。

此外,本综述还探讨了智能交通系统中的先进学习技术与挑战。Ramesh et al. (2025) 整合了深度强化迁移学习(DRTL)、VANETs 和可解释人工智能(XAI), 提升了ITS的适应性、可解释性和实时性。M. Li et al. (2025) 综述了强化学习在交通流预测中的应用,强调了其在捕捉时空关联性方面的优势。而Khalil et al. (2024) 则提供了一份全面的综述,探讨了深度学习和LLMs在ITS中的广泛应用前景,并指出了迁移学习、混合模型、隐私安全和超可靠低延迟通信等未来关键挑战。

## 主要发现

1.  **强化学习在动态决策中的核心地位:** 强化学习,特别是深度强化学习和多智能体强化学习,已成为解决城市交通动态、复杂决策问题的核心范式。它能够通过与环境交互学习最优策略,有效应对交通流的实时波动、多智能体间的复杂交互以及多目标优化需求。
2.  **运筹学作为基础的持续价值:** 尽管强化学习提供了数据驱动的解决方案,但运筹学在交通问题的数学建模、约束定义和性能评估方面仍然发挥着不可或缺的基础作用。许多强化学习问题本质上是运筹学问题的动态或大规模扩展。
3.  **大模型在行为仿真与场景理解中的新兴潜力:** 大规模语言模型展现出在模拟人类复杂行为、生成真实交通场景以及辅助决策支持方面的巨大潜力。它们能够提升交通仿真模型的真实性,并有望作为智能体的高级“大脑”融入强化学习框架。
4.  **多智能体协作与异步性处理的重要性:** 城市交通系统本质上是多智能体系,智能体间的协作与冲突解决至关重要。针对异步性、公平性和安全性等挑战,研究者们提出了创新的MARL框架和策略。
5.  **跨学科融合是未来趋势:** 将强化学习、运筹学与大模型相结合,以及与图网络、迁移学习、可解释AI等其他先进技术融合,是提升智能交通系统性能的关键。这种融合能够弥补单一技术的局限性,实现更全面、更鲁棒的解决方案。

## 研究缺口与未来方向

尽管取得了显著进展,但基于大模型、强化学习与运筹学的城市交通研究仍面临诸多挑战和研究缺口:

1.  **大模型与强化学习的深度融合机制:** 目前,LLMs在交通领域的应用尚处于早期阶段,主要集中在仿真和辅助决策。如何将LLMs的语义理解、推理和行为生成能力与强化学习的决策优化能力进行深度、高效的融合,构建真正

---

## 页面 31

智能的交通智能体,是一个重要的研究方向。例如,LLMs可以为RL 智能体提供高级别的目标设定、策略解释或情境感知,而RL则负责低级别的实时决策。

2.  **可解释性与鲁棒性:** 深度强化学习模型通常是“黑箱”模型,其决策过程难以解释,这在安全性要求极高的交通领域是一个严重问题。未来的研究需要进一步探索可解释人工智能(XAI)技术,以提高模型的透明度和可信度。同时,模型在面对未见过或对抗性场景时的鲁棒性也需加强。
3.  **大规模真实世界部署与数据挑战:** 现有研究多基于仿真环境进行验证。将这些先进模型部署到大规模真实城市交通系统中,将面临数据获取、隐私保护、计算资源、通信延迟以及与现有基础设施兼容性等实际挑战。如何设计高效、可扩展且能处理不完整、不准确数据的算法是关键。
4.  **多目标优化与公平性考量:** 城市交通系统涉及多方利益主体(驾驶员、乘客、行人、平台、政府),优化目标往往是多维且相互冲突的。未来的研究需要更深入地探索多目标强化学习和公平性强化学习,以在效率、公平、安全和环境效益之间取得平衡。
5.  **跨域迁移与泛化能力:** 不同城市、不同区域的交通特性差异巨大。如何利用迁移学习技术,使在一个区域训练的模型能够快速适应并泛化到其他区域,减少重新训练的成本,是提升实际应用价值的关键。
6.  **人机协作与混合智能:** 未来的智能交通系统将是人机共存的混合智能系统。如何设计强化学习和大模型,使其能够与人类驾驶员、交通管理者进行有效协作,理解人类意图,并提供恰当的辅助决策,是重要的研究方向。

综上所述,基于大模型、强化学习与运筹学的城市交通研究正蓬勃发展,为解决复杂的城市交通问题提供了前所未有的机遇。通过持续的跨学科合作和技术创新,我们有望构建一个更加智能、高效、公平和可持续的未来城市交通系统,为全球城市的可持续发展贡献力量。

## 参考文献

Dong, J., Yassine, A., Armitage, A., & Hossain, M. S. (2023). Multi-agent reinforcement learning for intelligent V2G integration in future transportation systems. *IEEE Transactions on Intelligent Transportation Systems*, 24(12), 15974–15983.
https://doi.org/10.1109/tits.2023.3284756

Du, K., Lee, E., Ma, Q., Su, Z., Zhang, S., & Lo, H. K. (2025). Modeling metro passenger routing choices with a fully differentiable end-to-end simulation-based optimization (SBO) approach. *Transportation Science*, 59(4), 802–822.
https://doi.org/10.1287/trsc.2024.0557

Dui, H., Zhang, S., Liu, M., Dong, X., & Bai, G. (2024). IoT-enabled real-time traffic monitoring and control management for intelligent transportation systems. *IEEE Internet of Things Journal*, 11(9), 15842–15854. https://doi.org/10.1109/jiot.2024.3351908

---

## 页面 32

Han, G., Zheng, Q., Liao, L., Tang, P., Li, Z., & Zhu, Y. (2022). Deep reinforcement learning for intersection signal control considering pedestrian behavior. *Electronics*, 11(21), 3519. https://doi.org/10.3390/electronics11213519

Jia, J., Liu, D., Ge, L., & Lu, F. (2024). Research on optimization configuration of urban substation charging station based on deep reinforcement learning algorithm. *2024 8th International Conference on Electrical, Mechanical and Computer Engineering (ICEMCE)*, 119–123. https://doi.org/10.1109/icemce64157.2024.10862876

Kang, J., Choi, Y., & Sohn, K. (2025). Simultaneous optimization of traffic signal control and vehicle platooning scheme based on connected and automated vehicle (CAV) technology. *IEEE Access*, 13, 99744–99757. https://doi.org/10.1109/access.2025.3577165

Khalil, R. A., Safelnasr, Z., Yemane, N., Kedir, M., Shafiqurrahman, A., & SAEED, N. (2024). Advanced learning technologies for intelligent transportation systems: Prospects and challenges. *IEEE Open Journal of Vehicular Technology*, 5, 397–427. https://doi.org/10.1109/ojvt.2024.3369691

Li, M., Zhou, D., & Zhang, S. (2025). The application of reinforcement learning in traffic flow prediction: Advantages, problems, and prospects. *ITM Web of Conferences*, 70, 01010. https://doi.org/10.1051/itmconf/20257001010

Li, Q., Meng, H., & Zhuo, L. (2025). Reinforcement learning-based vehicle travel path reconstruction from sparse automatic licence plate recognition data. *Annals of GIS*, 31(2), 207–219. https://doi.org/10.1080/19475683.2025.2453553

Li, S., Kaisar, E. I., Kwak, D., Hu, B., & Liu, D. (2025). Optimizing heterogeneous capacitated vehicle routing with linformer and multi-relationship decoding: A deep reinforcement learning approach. *Transportation Research Record: Journal of the Transportation Research Board*. https://doi.org/10.1177/03611981251338719

Liang, Y. (2024). Fairness-aware dynamic ride-hailing matching based on reinforcement learning. *Electronics*, 13(4), 775. https://doi.org/10.3390/electronics13040775

Liu, J., Chen, W., & Sun, L. (2024). A data-driven optimization framework for static rebalancing operations in bike sharing systems. *INFORMS Journal on Computing*. https://doi.org/10.1287/ijoc.2022.0182

Liu, Y., Liao, X., Ma, H., Liu, J., Jadhav, R., & Ma, J. (2025). *MobiVerse: Scaling urban mobility simulation with hybrid lightweight domain-specific generator and large language models*. arXiv. https://doi.org/10.48550/ARXIV.2506.21784

Liu, Y., Pan, Y., Zeng, Y., Ma, B., & Prashant, D. (2024). *Active legibility in multiagent reinforcement learning*. arXiv. https://doi.org/10.48550/ARXIV.2410.20954

N, A., & A, J. M. Rani. (2025). AI powered reinforcement learning algorithm for reducing traffic accidents. *2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and*

---

## 页面 33

Telecommunication Engineering (RMKMATE), 1–6.
https://doi.org/10.1109/rmkmate64874.2025.11042597

Neria, G., & Tzur, M. (2024). The dynamic pickup and allocation with fairness problem.
*Transportation Science*, 58(4), 821–840.
https://doi.org/10.1287/trsc.2023.0228

Ramesh, S. S. S., Banu, J. F., Kavitha, V. R., & Ramesh, T. (2025). Enhancing intelligent transportation systems in smart cities using <scp>VANETs</scp> with deep reinforcement transfer learning and explainable <scp>AI</scp>. *Transactions on Emerging Telecommunications Technologies*, 36(8).
https://doi.org/10.1002/ett.70219

Taherinavid, S., Moravvej, S. V., Chen, Y.-L., Yang, J., Ku, C. S., & Yee, P. L. (2024).
Automatic transportation mode classification using a deep reinforcement learning approach with smartphone sensors. *IEEE Access*, 12, 514–533.
https://doi.org/10.1109/access.2023.3346875

Tong, S., Liu, Y., Mišić, J., Chang, X., Zhang, Z., & Wang, C. (2023). Joint task offloading and resource allocation for fog-based intelligent transportation systems: A UAV-enabled multi-hop collaboration paradigm. *IEEE Transactions on Intelligent Transportation Systems*, 24(11), 12933–12948.
https://doi.org/10.1109/tits.2022.3163804

Tresca, L., Schmidt, C., Harrison, J., Rodrigues, F., Zardini, G., Gammelli, D., & Pavone, M. (2025). *Robo-taxi fleet coordination at scale via reinforcement learning*. arXiv.
https://doi.org/10.48550/ARXIV.2504.06125

Voronovskyi, M. I., & Yurchak, I. Y. (2025). OPTIMIZING ROAD TRAFFIC THROUGH REINFORCEMENT LEARNING. *Computer Systems and Network*, 7(1), 60–67.
https://doi.org/10.23939/csn2025.01.060

Wang, J., & Sun, L. (2021). Reducing bus bunching with asynchronous multi-agent reinforcement learning. *Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence*, 426–433.
https://doi.org/10.24963/ijcai.2021/60

Wang, K., Liu, Q., Li, X., & Yang, F. (2024). AF-DQN: A large-scale decision-making method at unsignalized intersections with safe action filter and efficient exploratory training strategy. *2024 IEEE Intelligent Vehicles Symposium (IV)*, 337–344.
https://doi.org/10.1109/iv55156.2024.10588826

---

## 页面 34

同时考虑了交通效率和安全性,并纳入了行人和车辆在交叉口的等待时间。通过改进离散交通状态编码(DTSE)方法来定义更全面的状态和奖励,并采用多进程操作方法同时运行多个环境进行训练以提高模型效率。在SUMO仿真软件上进行的实验结果表明,与Dueling DQN相比,该方法能显著减少等待时间(58.76%)和等待人数(51.54%),有效提升了交叉口的整体效率和安全性。这突出强调了RL在处理多目标优化和复杂交通参与者交互方面的能力。

Voronovskyi & Yurchak (2025)也分析了基于模型无关强化学习算法(如Q-Learning 和 Deep Q-Learning)优化城市交通的现代方法,特别是在动态路况下控制交通信号灯的应用。通过SUMO环境的仿真结果证明,实施此类算法能显著减少交叉口排队并提高交通网络的容量。该研究指出,Deep Q-Learning 能够更有效地处理大量数据,包括来自物联网传感器和V2X技术的信息,从而实现对不断变化的交通状况的现实适应。这进一步证实了深度强化学习在处理大规模、高维交通数据和实现实时自适应控制方面的优越性。

在互联自动驾驶车辆(CAV)技术背景下,Kang et al. (2025)提出了一种基于强化学习算法,用于同时优化交通信号控制和车辆编队方案。该研究关注在严重拥堵的交通条件下,如何同步停在停车线处的车辆,以在绿灯启动时最大化交通吞吐量,消除启动延迟。其提出的方法在交通流过饱和时,优于不带编队的自适应交通信号控制和不带交通灯的完全自动化交叉口管理(AIM)。这展示了RL在整合CAV技术,实现更精细化、协同化的交通管理方面的巨大潜力,尤其是在未来CAV普及的场景中。

为了应对交通拥堵和交通事故,N & A (2025)提出了一种混合优势 Actor-Critic (A2C)算法,用于实时交通优化。该研究指出,传统的基于规则的路由和固定配时信号控制在交通状况变化时效果不佳,而DQN和Q-learning等机器学习方法在训练稳定性、实时适应性和可扩展性方面存在挑战。A2C算法结合了基于策略和基于价值的强化学习,通过Actor网络动态选择交通控制操作,Critic网络评估这些操作,以确保最优决策。实验结果表明,该方法将等待时间减少了35%,事故减少了30%,交通拥堵减少了40%,并具有更快的收敛速度、更高的灵活性和更好的稳定性。这表明更先进的RL算法,如A2C,能够有效解决传统RL方法在实际应用中的局限性,提供更鲁棒和高效的交通管理方案。

## 2.2 共享出行与车队调度优化

共享出行服务(如网约车、共享单车)在城市中日益普及,但其运营效率和用户体验严重依赖于有效的车队调度和资源分配策略。强化学习能够处理这些问题中的动态性和不确定性。

Tresca et al. (2025)针对自动驾驶移动按需(AMoD)系统中的机器人出租车车队协调问题,提出了一种新颖的决策框架。该框架将数学建模与数据驱动技术相结合,通过强化学习的视角来解决AMoD协调问题,并提出了一个基于图网络的框架,利用图表示学习、强化学习和经典运筹学工具的优势。在各种仿真场景下的广泛评

---

## 页面 35

估表明,该方法在系统性能、计算效率和泛化能力方面均优于现有方法。这强调了 RL 在处理大规模、动态车队调度问题中的有效性,特别是与图神经网络结合时,能够更好地捕捉交通网络的拓扑结构和车辆之间的复杂交互。

Liang (2024) 关注网约车匹配问题中的公平性,提出了一种面向公平性的动态匹配算法。该研究指出,现有研究缺乏对司机收入公平性的探索,且部分算法在工业环境中不具实用性。为了解决这些不足,他们开发了一种基于强化学习的动态匹配算法,有效优化了平台整体效率(预期司机总收入)和司机收入公平性(加权摊销公平性信息的熵)。该算法引入了匹配结果对后续匹配的时间依赖性,并利用强化学习预测这些时间依赖性,克服了传统匹配算法仅依赖历史数据和当前情况进行订单分配的局限性。通过引入时间窗匹配模型、剪枝操作和度量表示调整等优化方案,增强了算法对大规模数据集的适应性和可扩展性。在真实数据集上的实验表明,该算法在公平性、平台效用和匹配效率方面均优于传统算法。这展示了RL在处理多目标优化(效率与公平性)和动态决策方面的强大能力,为共享出行平台提供了更具社会责任感的解决方案。

在公共交通领域,J. Wang & Sun (2021) 提出了一种异步多智能体强化学习(ASMR)方法来减少公交车“扎堆”现象。公交车扎堆是城市公交系统常见的现象,严重影响服务可靠性和效率。该研究将线路级公交车队控制问题建模为ASMR 问题,并扩展了经典的Actor-Critic 架构以处理异步特性(控制动作仅在公交车到达站点时发生)。他们设计了一种新颖的Critic 网络,利用图注意力神经网络进行归纳学习以评估策略,从而帮助智能体更有效地优化其策略。在真实公交服务和乘客需求数据上的评估表明,该模型优于传统的基于车头时距的控制方法和现有的MARL方法。这突出了MARL 在解决复杂、异步多智能体协作问题中的优势,为提升城市公共交通服务质量提供了有效途径。

## 2.3 自动驾驶与多智能体协作决策

自动驾驶车辆(AVs)和互联自动驾驶车辆(CAVs)是未来智能交通系统的核心组成部分。强化学习在自动驾驶车辆的决策制定、路径规划以及多智能体协作方面发挥着关键作用。

K. Wang et al. (2024) 提出了一种名为AF-DQN的大规模决策方法,用于非信号交叉口处的互联自动驾驶车辆(CAVs)。该研究关注非信号交叉口交通量大、交互复杂、风险显著的特点,提出AF-DQN方法,使AVs能够有效过滤潜在危险的变道动作并执行安全动作。他们设计了一个考虑安全、任务完成和合规性等多因素的多目标奖励函数,并引入了一种探索性训练策略,使智能体能够先在简单场景中学习,再解决复杂场景中的驾驶任务。实验结果表明,探索性训练加速了模型训练速度并提高了训练效果,AF-DQN方法在安全性、效率和遵守交通规则方面均优于基线方法。这表明RL在自动驾驶决策中,尤其是在复杂和高风险场景下,能够通过精心设计的算法和训练策略,有效提升安全性和效率。

---

## 页面 36

在多智能体强化学习(MARL)领域,Liu et al. (2024)提出了一个多智能体主动可读性框架,以提高智能体的性能。该研究指出,多智能体序列决策问题在城市交通、自动驾驶等关键应用中普遍存在。受可读性研究的启发(即智能体通过行为揭示其意图),该框架允许智能体执行可读性动作,从而帮助其他智能体优化其行为。通过模拟常见场景的问题域,实验结果表明,与几种MARL算法相比,新框架更高效且训练时间更短。这为未来自动驾驶车辆之间的协同决策提供了新的思路,通过提升智能体行为的可预测性和可理解性,增强了多智能体系统的整体协作效率和安全性。

电动汽车(EVs)作为未来智能交通系统的骨干,其与电网的集成(V2G)是实现可持续发展的关键。Dong et al. (2023)提出了一种多智能体强化学习(MARL)机制,用于未来交通系统中智能V2G集成。该机制调度EV电池的日前放电过程,以优化电网的削峰性能。MARL通过允许智能体(即EVs)自主决策,克服了能源预测的不准确性。这些智能体以集中式方式训练,但进行本地决策,以保持自主性和隐私。实验证明,该MARL协调和调度机制能够有效削平峰值负荷。这展示了MARL 在跨领域(交通与能源)协同优化中的应用潜力,为构建更智能、更可持续的城市基础设施提供了解决方案。

## 2.4 交通行为分析与预测

准确的交通行为分析和流量预测是智能交通系统有效运行的基础。强化学习也开始被应用于这些数据驱动的任务中。

Taherinavid et al. (2024) 提出了一种基于深度强化学习的自动交通模式分类模型,利用智能手机传感器数据(加速度计、磁力计和陀螺仪)。该研究旨在通过增强特征提取和将分类任务视为一系列结构化决策事件来提高交通模式分类的精度。模型采用改进的差分进化(DE)算法初始化权重,并设计了专门的智能体-环境关系,通过正确分类获得奖励,并对不频繁模式的准确分类给予额外奖励。UCB技术用于动作选择,以促进深度知识学习。在HTC 数据集上的评估显示,该模型取得了0.88±0.03的准确率和0.87±0.02的F-measure,证明了其在大规模交通模式分类任务中的有效性。这表明RL不仅可以用于控制,也可以用于复杂的模式识别和分类任务,从传感器数据中提取有价值的交通行为洞察。

Q. Li et al. (2025) 提出了一种基于强化学习的车辆出行路径重建模型,用于从稀疏的自动车牌识别(ALPR)数据中获取大规模车辆轨迹。由于ALPR传感器分布稀疏,车辆轨迹往往不完整。该研究首先采用最大熵逆强化学习(MaxEnt IRL)方法从真实数据中学习车辆路径选择策略(即奖励函数),然后通过整合目的地奖励来制定全面的奖励函数,最后利用 Q-learning 算法基于该奖励函数重建相邻 ALPR传感器之间的车辆出行路径。在100对相邻 ALPR传感器上的评估表明,该模型显著优于两种基线方法,与真实路径的偏差分别减少了24.3%和22.5%。这展示了RL 在处理不完整交通数据,进行智能推断和重建方面的能力,对于弥补数据缺失、提升交通流理解具有重要意义。

---

## 页面 37

M. Li et al. (2025) 综述了强化学习在交通流预测(TFP)中的应用,并讨论了其优势、问题和前景。该研究指出,传统TFP方法难以捕捉交通网络中交通空间分布与各位置交通状况时间演变之间的相互依赖关系。文章总结了参数化预测、浅层机器学习和深度学习等传统TFP方法,并强调了如何充分提取交通流时空相关性(SCTF)是基于深度学习预测模型亟待解决的问题。随着科技进步,越来越多的学者尝试将强化学习融入TFP,实验结果表明,RL能够更大程度地减少车辆排队时间平均延误,并缓解空气污染。该综述全面比较了各种方法的优缺点,并提出了现有问题和未来发展愿景。这表明RL在处理交通流预测中的动态性和时空复杂性方面具有独特优势,能够提供更精准、更具决策支持价值的预测结果。

综上所述,强化学习在智能交通系统中的应用范围广泛,从底层的交通信号控制到高层的车队调度和自动驾驶决策,再到数据驱动的交通行为分析和预测,都展现出强大的能力。不同RL算法(如DQN、A2C、MARL)在解决特定问题时各有侧重,例如 MARL 在多智能体协作和分布式决策中表现出色,而深度RL则能处理高维状态空间。然而,RL在实际应用中仍面临挑战,包括状态和奖励函数的设计复杂性、训练过程的收敛性和稳定性、计算资源的消耗、以及如何确保决策的安全性和公平性等。未来的研究需要进一步探索更高效、更鲁棒、更可解释的RL算法,并将其与实际交通系统深度融合,以实现更智能、更人性化的城市交通管理。

# 3. 运筹学方法及其与机器学习/强化学习的融合

运筹学(Operations Research, OR)作为一门应用数学学科,长期以来一直是城市交通研究的基石。它通过数学建模、优化算法和统计分析,为交通规划、调度、路由和资源分配等问题提供严谨的理论框架和解决方案。然而,面对城市交通系统日益增长的复杂性、动态性和不确定性,纯粹的运筹学方法在处理大规模实时数据和适应快速变化的环境时,往往会遇到计算瓶颈和模型假设的局限性。因此,将运筹学与机器学习(ML)和强化学习(RL)等数据驱动技术相结合,已成为当前研究的热点和趋势,旨在融合两者的优势,构建更强大、更灵活的解决方案。

## 3.1 动态路由与资源分配优化

动态路由和资源分配是城市物流、共享出行和应急响应等领域的核心问题,其特点是信息随时间逐步到达且具有不确定性。运筹学提供了问题建模的基础,而ML/RL则增强了其在动态环境下的适应性。

Neria & Tzur (2024) 提出了一个动态取货和分配与公平性问题,该问题涉及在供应数量和可用时间未知的情况下,实时做出路由和分配决策。他们将此问题建模为一个随机动态路由和资源分配问题,目标是在尽可能多地交付货物的同时,实现对需求点的公平分配。尽管马尔可夫决策过程(MDP)可以形式化该问题,但其面临维度灾难。因此,该研究开发了一个启发式框架,创新性地结合了运筹学和机器学习:使用大邻域搜索(LNS)探索可能的决策,并结合神经网络(NN)模型来近似给定任何状态和动作的未来价值,并通过一种新的强化学习方法来训练NN,以

---

## 页面 38

应对决策空间过大的情况。在柏林食品银行数据和随机生成数据集上的数值实验表明,该启发式方法优于三种基准解决方案。这篇论文是运筹学与机器学习/强化学习深度融合的典范,展示了如何利用OR提供问题结构和搜索空间,同时利用ML/RL 处理不确定性和动态决策,实现复杂组合优化问题的有效求解。

在异构容量车辆路径问题(HCVRP)方面,S. Li et al. (2025)提出了一种基于深度强化学习的方法,结合Linformer 和多关系解码器来优化城市杂货配送中的异构车队路由。HCVRP是一个典型的运筹学问题,传统精确算法和启发式算法在问题规模扩大时面临计算挑战。该研究引入了一种新的神经网络架构,包含Linformer 以显著降低计算需求,以及一个多关系节点选择解码器以提高决策的准确性和效率。通过广泛实验,该DRL框架在不同问题规模和目标下,持续超越传统启发式算法和现有DRL模型,提供更优的解决方案质量和计算效率。这再次证明了RL在解决传统 OR问题中的潜力,特别是在处理大规模、高维决策空间时,通过引入先进的神经网络架构,能够有效提升求解效率和质量。

无人机(UAVs)在智能交通系统(ITS)中的应用日益广泛,特别是在通信范围扩展和快速部署方面。Tong et al. (2023)提出了一种无人机赋能的多跳协作雾计算系统模型,用于联合任务卸载和资源分配。该研究将问题形式化为一个混合整数非线性规划(MINLP)问题,涉及用户关联、无人机关联、任务卸载、传输功率、计算资源分配和无人机位置优化。为了解决这个非凸问题,他们提出了一种多跳协作算法来推导每个无人机的最优任务卸载和资源分配决策。仿真结果证明了无人机赋能多跳协作雾计算系统的优越性以及所提方案的有效性。尽管这篇论文主要侧重于运筹学算法设计来解决复杂的MINLP问题,但其所处理的动态资源分配和网络优化问题,为未来与RL结合提供了广阔空间,例如RL可以用于实时调整无人机位置或任务卸载策略以应对动态环境变化。

## 3.2 城市交通网络建模与系统级优化

城市交通网络建模和系统级优化是运筹学在交通领域的核心应用,旨在理解交通流行为、预测系统性能并优化基础设施利用。与ML/RL的结合,使得这些模型能够更好地适应实际数据的复杂性和动态性。

Du et al. (2025) 提出了一种新颖的乘客路径选择模型,用于建模地铁乘客在复杂城市区域的路由选择行为。该模型结合了一个考虑乘客流量、排队、拥堵和换乘延误的地铁模拟器。为了校准模型,该研究提出了一种利用完全可微分的端到端基于模拟的优化(SBO)框架,通过迭代反向传播(IB)算法自动分析性地计算梯度。SBO框架整合了智能卡数据和列车载荷等多源数据,以校准最符合观测数据的路径选择参数。该框架的完全可微分性使其能够校准超过20,000个乘客路径选择比率,覆盖每个OD对。为了进一步提高效率,还提出了一种基于矩阵的优化(MBO)机制,为SBO提供更好的初始值。混合优化算法(MBO和SBO结合)有效地校准了模型,并在合成数据上展示了高精度。该研究随后将SBO框架扩展到用户均衡公式,并结合了考虑拥堵的路径选择模型和迭代地铁模拟。这篇论文是

---

## 页面 39

运筹学(优化和模拟)与机器学习(可微分编程和自动梯度计算)深度结合的典范, 展示了如何通过数据驱动的优化方法,实现对复杂交通系统行为的精确建模和校准。

共享单车系统在城市中广泛部署,但由于需求在地理和时间上的不平衡,夜间需要进行系统范围内的单车再平衡操作,以维持高服务水平并最小化因缺货或超载造成的损失。J. Liu et al. (2024) 提出了一个数据驱动的优化框架,用于静态再平衡操作。该研究首先开发了基于深度学习的预测器,捕捉站点级需求的时间依赖性、天气条件影响以及附近站点的需求替代效应。基于需求率,开发了基于序列模拟的需求损失估计器,以找到导致最小预期需求损失的最优再平衡数量。然后,他们建立了一个混合整数线性规划模型来优化再平衡车辆的路径问题。为了解决计算挑战,他们提出了一种数据驱动的分解算法,通过将多车辆路径问题分解为更小、可处理的单车辆路径问题来支持多车辆多访问再平衡策略,这些问题可以并行求解。在纽约市Citi Bike 真实数据上的广泛数值实验证明了所提单车需求预测器的准确性、需求替代效应的影响以及数据驱动优化框架的效率。这篇论文是运筹学(MILP、分解算法)与深度学习(预测器)结合的又一成功案例,展示了如何利用ML 处理数据预测和不确定性,然后将预测结果输入到OR模型中进行优化决策。

电动汽车充电站的优化配置是“双碳”政策背景下城市交通发展的重要一环。Jia et al. (2024) 提出了一种基于DQN(Deep Q-Network)算法的电动汽车典型快充站优化运行配置方法,并具体介绍了变电站充电配置的内容。该研究旨在通过分析站内分布式电源的输出特性和电动汽车的充电行为模式,基于经济和运行效率优化各充电站的容量,并构建一个典型的快充站优化运行配置模型。该模型不仅受站内功率平衡和分布式电源输出等关键因素的约束,还考虑了变电站充电配置的优化,以确保充电站的高效运行和电网的稳定性。通过使用DQN算法替代传统的遗传优化算法求解模型的最优解,实现了充电站配置的精细化管理。实证分析验证了所提方法的有效性和可行性。这篇论文展示了强化学习(DQN)如何被应用于解决传统的运筹学优化问题,尤其是在具有动态性和不确定性的能源管理和基础设施配置领域。

综上所述,运筹学为城市交通问题提供了坚实的数学基础和优化框架,而机器学习和强化学习则为其注入了数据驱动的智能和动态适应能力。混合方法在处理动态路由、资源分配、网络建模和系统级优化等复杂问题时,能够充分发挥两者的优势,弥补单一方法的不足。例如,OR可以定义问题的目标函数和约束条件,提供结构化的决策空间,而ML/RL则可以学习复杂的非线性关系、处理不确定性、生成实时决策策略。这种融合不仅提升了模型的预测精度和决策效率,也使得解决方案更具鲁棒性和实用性。未来的研究将继续探索更深层次的融合机制,例如将OR的领域知识嵌入到 ML/RL模型的结构中,或者利用ML/RL来加速OR算法的求解过程,从而应对更具挑战性的城市交通问题。

---

## 页面 40

4. 综合应用、挑战与未来展望

城市交通研究正处于一个由大规模语言模型、强化学习和运筹学共同驱动的转型时期。这些先进技术的融合,为解决城市交通的复杂性和动态性问题提供了前所未有的机遇,同时也带来了新的挑战。本章将综合现有研究发现,探讨这些技术的集成应用,并展望未来的研究方向。

现有文献清晰地展示了这三种技术在城市交通不同层面的应用。大规模语言模型 (LLMs) 以其强大的文本理解和生成能力,在城市出行模拟中展现出提升行为真实性和情境感知决策的潜力,如Liu et al. (2025)提出的MobiVerse 框架,通过LLMs 实现大规模、动态的出行计划调整。Khalil et al. (2024)的综述也强调了LLMs 在交通流预测、车辆检测和自动驾驶等方面的广阔前景。LLMs能够处理和分析海量的非结构化数据,从而更精准地理解交通参与者的意图和行为模式,这是传统交通模型难以企及的。然而,LLMs的计算成本、可解释性以及多模态数据处理能力仍是其在交通领域广泛应用的关键挑战。

强化学习(RL)则在智能交通系统的动态决策和控制方面发挥着核心作用。从交通信号控制(如Han et al. (2022)考虑行人行为的信号控制,Voronovskyi & Yurchak (2025)的Q-Learning/DQL应用,Kang et al. (2025)的信号控制与车辆编队协同优化,以及N & A (2025)的混合A2C算法),到共享出行车队调度(如Tresca et al. (2025)的机器人出租车车队协调,Liang (2024)的公平性网约车匹配,J. Wang & Sun (2021)的异步MARL减少公交扎堆),再到自动驾驶决策和多智能体协作(如K. Wang et al. (2024)的非信号交叉口CAV决策,Liu et al. (2024)的多智能体主动可读性框架,Dong et al. (2023)的MARL用于V2G集成),RL都展现出强大的自适应学习和实时决策能力。此外,RL也被应用于交通行为分析和预测,例如 Taherinavid et al. (2024) 利用DRL进行交通模式分类,Q. Li et al. (2025) 基于RL重建车辆路径,以及M. Li et al. (2025) 综述了RL在交通流预测中的应用。RL的优势在于其能够通过试错学习在复杂动态环境中找到最优策略,但其挑战在于状态和奖励函数的设计、训练效率、收敛稳定性以及在真实世界部署时的安全性保障。

运筹学(OR)作为优化决策的科学,为交通问题的数学建模和算法设计提供了坚实基础。其与机器学习/强化学习的融合,形成了强大的混合方法,能够有效解决动态路由、资源分配、网络建模和系统级优化等复杂问题。例如,Neria & Tzur (2024)将OR(LNS)与ML/RL(NN近似未来价值)结合,解决了动态取货和分配与公平性问题。S. Li et al. (2025)采用DRL(Linformer 和多关系解码器)优化异构容量车辆路径问题。Tong et al. (2023)则通过MINLP模型和多跳协作算法解决了无人机赋能的联合任务卸载和资源分配问题。在城市交通网络建模方面,Du et al. (2025)提出了基于SBO的地铁乘客路径选择模型,将OR(模拟优化)与ML(可微分编程)深度融合。J. Liu et al. (2024)结合深度学习预测器和MILP/分解算法,优化了共享单车再平衡操作。Jia et al. (2024)则利用DQN算法优化电动汽车充电站的配置。这些混合方法充分利用了OR在问题结构化和优化理论上的优势,

---

